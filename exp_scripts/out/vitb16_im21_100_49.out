No pretrained configuration specified for vit_base_patch16_224_in21k model. Using a default. Please add a config to the model pretrained_cfg registry or pass explicitly.
Namespace(batch_size=64, continue_from_epoch=-2, seed=0, num_epochs=5, experiment_name='vitb16_im21_100', use_gpu=True, weight_decay_coefficient=0.0005, learning_rate=0.001, model='vitb16', pretrain='imagenet21k', dataloader='birds', height=100, width=100)
Number of training samples:  4495
Number of validation samples:  1499
Number of testing samples:  5794
Number of classes: 200
could not load layer: head.weight, mismatch shape torch.Size([200, 768]) ,torch.Size([11221, 768])
could not load layer: head.bias, mismatch shape torch.Size([200]) ,torch.Size([11221])
Use Multi GPU 0
here
System learnable parameters
DataParallel(
  (module): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (patch_drop): Identity()
    (norm_pre): Identity()
    (blocks): Sequential(
      (0): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (1): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (2): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (3): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (4): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (5): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (6): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (7): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (8): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (9): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (10): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (11): Block(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=768, out_features=2304, bias=False)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (fc_norm): Identity()
    (head_drop): Dropout(p=0.0, inplace=False)
    (head): Linear(in_features=768, out_features=200, bias=True)
  )
)
  0%|          | 0/71 [00:00<?, ?it/s]  1%|▏         | 1/71 [00:11<13:18, 11.41s/it]loss: 1.0001, accuracy: 1.0000:   1%|▏         | 1/71 [00:11<13:18, 11.41s/it]loss: 1.0001, accuracy: 1.0000:   3%|▎         | 2/71 [00:13<06:38,  5.78s/it]loss: 1.0424, accuracy: 1.0000:   3%|▎         | 2/71 [00:13<06:38,  5.78s/it]loss: 1.0424, accuracy: 1.0000:   4%|▍         | 3/71 [00:15<04:29,  3.96s/it]loss: 1.0379, accuracy: 1.0000:   4%|▍         | 3/71 [00:15<04:29,  3.96s/it]loss: 1.0379, accuracy: 1.0000:   6%|▌         | 4/71 [00:16<03:27,  3.09s/it]loss: 1.0547, accuracy: 1.0000:   6%|▌         | 4/71 [00:16<03:27,  3.09s/it]loss: 1.0547, accuracy: 1.0000:   7%|▋         | 5/71 [00:18<02:53,  2.64s/it]loss: 1.0224, accuracy: 0.9844:   7%|▋         | 5/71 [00:18<02:53,  2.64s/it]loss: 1.0224, accuracy: 0.9844:   8%|▊         | 6/71 [00:20<02:32,  2.35s/it]loss: 1.0346, accuracy: 1.0000:   8%|▊         | 6/71 [00:20<02:32,  2.35s/it]loss: 1.0346, accuracy: 1.0000:  10%|▉         | 7/71 [00:22<02:18,  2.17s/it]loss: 1.0024, accuracy: 1.0000:  10%|▉         | 7/71 [00:22<02:18,  2.17s/it]loss: 1.0024, accuracy: 1.0000:  11%|█▏        | 8/71 [00:24<02:09,  2.05s/it]loss: 0.9784, accuracy: 1.0000:  11%|█▏        | 8/71 [00:24<02:09,  2.05s/it]loss: 0.9784, accuracy: 1.0000:  13%|█▎        | 9/71 [00:25<02:01,  1.97s/it]loss: 1.0131, accuracy: 1.0000:  13%|█▎        | 9/71 [00:25<02:01,  1.97s/it]loss: 1.0131, accuracy: 1.0000:  14%|█▍        | 10/71 [00:27<01:56,  1.91s/it]loss: 1.0192, accuracy: 1.0000:  14%|█▍        | 10/71 [00:27<01:56,  1.91s/it]loss: 1.0192, accuracy: 1.0000:  15%|█▌        | 11/71 [00:29<01:52,  1.88s/it]loss: 1.0186, accuracy: 1.0000:  15%|█▌        | 11/71 [00:29<01:52,  1.88s/it]loss: 1.0186, accuracy: 1.0000:  17%|█▋        | 12/71 [00:31<01:48,  1.84s/it]loss: 0.9965, accuracy: 1.0000:  17%|█▋        | 12/71 [00:31<01:48,  1.84s/it]loss: 0.9965, accuracy: 1.0000:  18%|█▊        | 13/71 [00:33<01:47,  1.85s/it]loss: 1.0357, accuracy: 0.9844:  18%|█▊        | 13/71 [00:33<01:47,  1.85s/it]loss: 1.0357, accuracy: 0.9844:  20%|█▉        | 14/71 [00:34<01:46,  1.87s/it]loss: 1.0293, accuracy: 1.0000:  20%|█▉        | 14/71 [00:34<01:46,  1.87s/it]loss: 1.0293, accuracy: 1.0000:  21%|██        | 15/71 [00:36<01:42,  1.84s/it]loss: 1.0587, accuracy: 0.9844:  21%|██        | 15/71 [00:36<01:42,  1.84s/it]loss: 1.0587, accuracy: 0.9844:  23%|██▎       | 16/71 [00:38<01:40,  1.82s/it]loss: 1.0215, accuracy: 0.9844:  23%|██▎       | 16/71 [00:38<01:40,  1.82s/it]loss: 1.0215, accuracy: 0.9844:  24%|██▍       | 17/71 [00:40<01:37,  1.81s/it]loss: 1.0163, accuracy: 1.0000:  24%|██▍       | 17/71 [00:40<01:37,  1.81s/it]loss: 1.0163, accuracy: 1.0000:  25%|██▌       | 18/71 [00:42<01:35,  1.79s/it]loss: 1.0337, accuracy: 0.9844:  25%|██▌       | 18/71 [00:42<01:35,  1.79s/it]loss: 1.0337, accuracy: 0.9844:  27%|██▋       | 19/71 [00:43<01:33,  1.80s/it]loss: 1.0245, accuracy: 0.9844:  27%|██▋       | 19/71 [00:43<01:33,  1.80s/it]loss: 1.0245, accuracy: 0.9844:  28%|██▊       | 20/71 [00:45<01:31,  1.79s/it]loss: 1.0148, accuracy: 1.0000:  28%|██▊       | 20/71 [00:45<01:31,  1.79s/it]loss: 1.0148, accuracy: 1.0000:  30%|██▉       | 21/71 [00:47<01:31,  1.83s/it]loss: 0.9827, accuracy: 1.0000:  30%|██▉       | 21/71 [00:47<01:31,  1.83s/it]loss: 0.9827, accuracy: 1.0000:  31%|███       | 22/71 [00:49<01:29,  1.82s/it]loss: 1.0102, accuracy: 0.9844:  31%|███       | 22/71 [00:49<01:29,  1.82s/it]loss: 1.0102, accuracy: 0.9844:  32%|███▏      | 23/71 [00:51<01:27,  1.81s/it]loss: 1.0104, accuracy: 1.0000:  32%|███▏      | 23/71 [00:51<01:27,  1.81s/it]loss: 1.0104, accuracy: 1.0000:  34%|███▍      | 24/71 [00:52<01:24,  1.80s/it]loss: 1.0307, accuracy: 1.0000:  34%|███▍      | 24/71 [00:52<01:24,  1.80s/it]loss: 1.0307, accuracy: 1.0000:  35%|███▌      | 25/71 [00:54<01:22,  1.79s/it]loss: 1.0236, accuracy: 1.0000:  35%|███▌      | 25/71 [00:54<01:22,  1.79s/it]loss: 1.0236, accuracy: 1.0000:  37%|███▋      | 26/71 [00:56<01:20,  1.78s/it]loss: 1.0372, accuracy: 1.0000:  37%|███▋      | 26/71 [00:56<01:20,  1.78s/it]loss: 1.0372, accuracy: 1.0000:  38%|███▊      | 27/71 [00:58<01:18,  1.78s/it]loss: 1.0184, accuracy: 0.9844:  38%|███▊      | 27/71 [00:58<01:18,  1.78s/it]loss: 1.0184, accuracy: 0.9844:  39%|███▉      | 28/71 [01:00<01:17,  1.81s/it]loss: 1.0030, accuracy: 1.0000:  39%|███▉      | 28/71 [01:00<01:17,  1.81s/it]loss: 1.0030, accuracy: 1.0000:  41%|████      | 29/71 [01:01<01:15,  1.80s/it]loss: 0.9854, accuracy: 1.0000:  41%|████      | 29/71 [01:01<01:15,  1.80s/it]loss: 0.9854, accuracy: 1.0000:  42%|████▏     | 30/71 [01:03<01:13,  1.80s/it]loss: 1.0008, accuracy: 1.0000:  42%|████▏     | 30/71 [01:03<01:13,  1.80s/it]loss: 1.0008, accuracy: 1.0000:  44%|████▎     | 31/71 [01:05<01:11,  1.80s/it]loss: 1.0100, accuracy: 1.0000:  44%|████▎     | 31/71 [01:05<01:11,  1.80s/it]loss: 1.0100, accuracy: 1.0000:  45%|████▌     | 32/71 [01:07<01:10,  1.80s/it]loss: 1.0067, accuracy: 1.0000:  45%|████▌     | 32/71 [01:07<01:10,  1.80s/it]loss: 1.0067, accuracy: 1.0000:  46%|████▋     | 33/71 [01:09<01:08,  1.81s/it]loss: 1.0288, accuracy: 1.0000:  46%|████▋     | 33/71 [01:09<01:08,  1.81s/it]loss: 1.0288, accuracy: 1.0000:  48%|████▊     | 34/71 [01:10<01:06,  1.80s/it]loss: 1.0338, accuracy: 1.0000:  48%|████▊     | 34/71 [01:10<01:06,  1.80s/it]loss: 1.0338, accuracy: 1.0000:  49%|████▉     | 35/71 [01:12<01:05,  1.82s/it]loss: 1.0079, accuracy: 0.9844:  49%|████▉     | 35/71 [01:12<01:05,  1.82s/it]loss: 1.0079, accuracy: 0.9844:  51%|█████     | 36/71 [01:14<01:03,  1.80s/it]loss: 1.0390, accuracy: 0.9844:  51%|█████     | 36/71 [01:14<01:03,  1.80s/it]loss: 1.0390, accuracy: 0.9844:  52%|█████▏    | 37/71 [01:16<01:01,  1.80s/it]loss: 1.0402, accuracy: 1.0000:  52%|█████▏    | 37/71 [01:16<01:01,  1.80s/it]loss: 1.0402, accuracy: 1.0000:  54%|█████▎    | 38/71 [01:18<00:59,  1.80s/it]loss: 0.9980, accuracy: 1.0000:  54%|█████▎    | 38/71 [01:18<00:59,  1.80s/it]loss: 0.9980, accuracy: 1.0000:  55%|█████▍    | 39/71 [01:19<00:57,  1.80s/it]loss: 1.0189, accuracy: 0.9688:  55%|█████▍    | 39/71 [01:19<00:57,  1.80s/it]loss: 1.0189, accuracy: 0.9688:  56%|█████▋    | 40/71 [01:21<00:55,  1.80s/it]loss: 1.0317, accuracy: 1.0000:  56%|█████▋    | 40/71 [01:21<00:55,  1.80s/it]loss: 1.0317, accuracy: 1.0000:  58%|█████▊    | 41/71 [01:23<00:53,  1.80s/it]loss: 1.0190, accuracy: 0.9844:  58%|█████▊    | 41/71 [01:23<00:53,  1.80s/it]loss: 1.0190, accuracy: 0.9844:  59%|█████▉    | 42/71 [01:25<00:52,  1.82s/it]loss: 1.0271, accuracy: 1.0000:  59%|█████▉    | 42/71 [01:25<00:52,  1.82s/it]loss: 1.0271, accuracy: 1.0000:  61%|██████    | 43/71 [01:27<00:51,  1.82s/it]loss: 1.0094, accuracy: 1.0000:  61%|██████    | 43/71 [01:27<00:51,  1.82s/it]loss: 1.0094, accuracy: 1.0000:  62%|██████▏   | 44/71 [01:28<00:48,  1.80s/it]loss: 1.0457, accuracy: 0.9531:  62%|██████▏   | 44/71 [01:28<00:48,  1.80s/it]loss: 1.0457, accuracy: 0.9531:  63%|██████▎   | 45/71 [01:30<00:46,  1.81s/it]loss: 1.0340, accuracy: 1.0000:  63%|██████▎   | 45/71 [01:30<00:46,  1.81s/it]loss: 1.0340, accuracy: 1.0000:  65%|██████▍   | 46/71 [01:32<00:44,  1.79s/it]loss: 1.0260, accuracy: 1.0000:  65%|██████▍   | 46/71 [01:32<00:44,  1.79s/it]loss: 1.0260, accuracy: 1.0000:  66%|██████▌   | 47/71 [01:34<00:42,  1.78s/it]loss: 1.0165, accuracy: 1.0000:  66%|██████▌   | 47/71 [01:34<00:42,  1.78s/it]loss: 1.0165, accuracy: 1.0000:  68%|██████▊   | 48/71 [01:36<00:41,  1.79s/it]loss: 1.0713, accuracy: 1.0000:  68%|██████▊   | 48/71 [01:36<00:41,  1.79s/it]loss: 1.0713, accuracy: 1.0000:  69%|██████▉   | 49/71 [01:37<00:39,  1.80s/it]loss: 1.0165, accuracy: 1.0000:  69%|██████▉   | 49/71 [01:37<00:39,  1.80s/it]loss: 1.0165, accuracy: 1.0000:  70%|███████   | 50/71 [01:39<00:37,  1.80s/it]loss: 1.0301, accuracy: 0.9844:  70%|███████   | 50/71 [01:39<00:37,  1.80s/it]loss: 1.0301, accuracy: 0.9844:  72%|███████▏  | 51/71 [01:41<00:35,  1.79s/it]loss: 1.0110, accuracy: 0.9844:  72%|███████▏  | 51/71 [01:41<00:35,  1.79s/it]loss: 1.0110, accuracy: 0.9844:  73%|███████▎  | 52/71 [01:43<00:34,  1.81s/it]loss: 1.0192, accuracy: 1.0000:  73%|███████▎  | 52/71 [01:43<00:34,  1.81s/it]loss: 1.0192, accuracy: 1.0000:  75%|███████▍  | 53/71 [01:45<00:32,  1.80s/it]loss: 1.0196, accuracy: 1.0000:  75%|███████▍  | 53/71 [01:45<00:32,  1.80s/it]loss: 1.0196, accuracy: 1.0000:  76%|███████▌  | 54/71 [01:46<00:30,  1.80s/it]loss: 1.0246, accuracy: 1.0000:  76%|███████▌  | 54/71 [01:46<00:30,  1.80s/it]loss: 1.0246, accuracy: 1.0000:  77%|███████▋  | 55/71 [01:48<00:28,  1.79s/it]loss: 1.0608, accuracy: 0.9844:  77%|███████▋  | 55/71 [01:48<00:28,  1.79s/it]loss: 1.0608, accuracy: 0.9844:  79%|███████▉  | 56/71 [01:50<00:27,  1.83s/it]loss: 1.0285, accuracy: 0.9844:  79%|███████▉  | 56/71 [01:50<00:27,  1.83s/it]loss: 1.0285, accuracy: 0.9844:  80%|████████  | 57/71 [01:52<00:25,  1.82s/it]loss: 0.9966, accuracy: 1.0000:  80%|████████  | 57/71 [01:52<00:25,  1.82s/it]loss: 0.9966, accuracy: 1.0000:  82%|████████▏ | 58/71 [01:54<00:23,  1.81s/it]loss: 1.0040, accuracy: 1.0000:  82%|████████▏ | 58/71 [01:54<00:23,  1.81s/it]loss: 1.0040, accuracy: 1.0000:  83%|████████▎ | 59/71 [01:55<00:21,  1.80s/it]loss: 1.0080, accuracy: 0.9844:  83%|████████▎ | 59/71 [01:55<00:21,  1.80s/it]loss: 1.0080, accuracy: 0.9844:  85%|████████▍ | 60/71 [01:57<00:19,  1.81s/it]loss: 1.0069, accuracy: 1.0000:  85%|████████▍ | 60/71 [01:57<00:19,  1.81s/it]loss: 1.0069, accuracy: 1.0000:  86%|████████▌ | 61/71 [01:59<00:18,  1.80s/it]loss: 1.0007, accuracy: 1.0000:  86%|████████▌ | 61/71 [01:59<00:18,  1.80s/it]loss: 1.0007, accuracy: 1.0000:  87%|████████▋ | 62/71 [02:01<00:16,  1.81s/it]loss: 1.0420, accuracy: 1.0000:  87%|████████▋ | 62/71 [02:01<00:16,  1.81s/it]loss: 1.0420, accuracy: 1.0000:  89%|████████▊ | 63/71 [02:03<00:14,  1.81s/it]loss: 1.0405, accuracy: 1.0000:  89%|████████▊ | 63/71 [02:03<00:14,  1.81s/it]loss: 1.0405, accuracy: 1.0000:  90%|█████████ | 64/71 [02:05<00:12,  1.82s/it]loss: 1.0634, accuracy: 0.9844:  90%|█████████ | 64/71 [02:05<00:12,  1.82s/it]loss: 1.0634, accuracy: 0.9844:  92%|█████████▏| 65/71 [02:06<00:10,  1.81s/it]loss: 1.0427, accuracy: 0.9844:  92%|█████████▏| 65/71 [02:06<00:10,  1.81s/it]loss: 1.0427, accuracy: 0.9844:  93%|█████████▎| 66/71 [02:08<00:09,  1.81s/it]loss: 1.0294, accuracy: 0.9844:  93%|█████████▎| 66/71 [02:08<00:09,  1.81s/it]loss: 1.0294, accuracy: 0.9844:  94%|█████████▍| 67/71 [02:10<00:07,  1.81s/it]loss: 1.0006, accuracy: 1.0000:  94%|█████████▍| 67/71 [02:10<00:07,  1.81s/it]loss: 1.0006, accuracy: 1.0000:  96%|█████████▌| 68/71 [02:12<00:05,  1.80s/it]loss: 1.0183, accuracy: 1.0000:  96%|█████████▌| 68/71 [02:12<00:05,  1.80s/it]loss: 1.0183, accuracy: 1.0000:  97%|█████████▋| 69/71 [02:13<00:03,  1.79s/it]loss: 1.0167, accuracy: 1.0000:  97%|█████████▋| 69/71 [02:13<00:03,  1.79s/it]loss: 1.0167, accuracy: 1.0000:  99%|█████████▊| 70/71 [02:15<00:01,  1.80s/it]loss: 1.0081, accuracy: 1.0000:  99%|█████████▊| 70/71 [02:15<00:01,  1.80s/it]loss: 1.0081, accuracy: 1.0000: 100%|██████████| 71/71 [02:16<00:00,  1.55s/it]loss: 0.9417, accuracy: 1.0000: 100%|██████████| 71/71 [02:16<00:00,  1.55s/it]loss: 0.9417, accuracy: 1.0000: 100%|██████████| 71/71 [02:16<00:00,  1.93s/it]
  0%|          | 0/24 [00:00<?, ?it/s]  4%|▍         | 1/24 [00:01<00:29,  1.28s/it]loss: 1.7446, accuracy: 0.7031:   4%|▍         | 1/24 [00:01<00:29,  1.28s/it]loss: 1.7446, accuracy: 0.7031:   8%|▊         | 2/24 [00:02<00:27,  1.27s/it]loss: 2.0910, accuracy: 0.6406:   8%|▊         | 2/24 [00:02<00:27,  1.27s/it]loss: 2.0910, accuracy: 0.6406:  12%|█▎        | 3/24 [00:03<00:26,  1.26s/it]loss: 1.9448, accuracy: 0.6875:  12%|█▎        | 3/24 [00:03<00:26,  1.26s/it]loss: 1.9448, accuracy: 0.6875:  17%|█▋        | 4/24 [00:05<00:24,  1.24s/it]loss: 1.7692, accuracy: 0.7188:  17%|█▋        | 4/24 [00:05<00:24,  1.24s/it]loss: 1.7692, accuracy: 0.7188:  21%|██        | 5/24 [00:06<00:23,  1.26s/it]loss: 1.8507, accuracy: 0.7500:  21%|██        | 5/24 [00:06<00:23,  1.26s/it]loss: 1.8507, accuracy: 0.7500:  25%|██▌       | 6/24 [00:07<00:22,  1.28s/it]loss: 1.6986, accuracy: 0.7656:  25%|██▌       | 6/24 [00:07<00:22,  1.28s/it]loss: 1.6986, accuracy: 0.7656:  29%|██▉       | 7/24 [00:08<00:21,  1.28s/it]loss: 1.5936, accuracy: 0.7969:  29%|██▉       | 7/24 [00:08<00:21,  1.28s/it]loss: 1.5936, accuracy: 0.7969:  33%|███▎      | 8/24 [00:10<00:20,  1.27s/it]loss: 1.8286, accuracy: 0.7031:  33%|███▎      | 8/24 [00:10<00:20,  1.27s/it]loss: 1.8286, accuracy: 0.7031:  38%|███▊      | 9/24 [00:11<00:19,  1.27s/it]loss: 1.9463, accuracy: 0.6875:  38%|███▊      | 9/24 [00:11<00:19,  1.27s/it]loss: 1.9463, accuracy: 0.6875:  42%|████▏     | 10/24 [00:12<00:17,  1.28s/it]loss: 1.9404, accuracy: 0.7188:  42%|████▏     | 10/24 [00:12<00:17,  1.28s/it]loss: 1.9404, accuracy: 0.7188:  46%|████▌     | 11/24 [00:14<00:16,  1.28s/it]loss: 1.8087, accuracy: 0.7188:  46%|████▌     | 11/24 [00:14<00:16,  1.28s/it]loss: 1.8087, accuracy: 0.7188:  50%|█████     | 12/24 [00:15<00:15,  1.28s/it]loss: 1.6891, accuracy: 0.7656:  50%|█████     | 12/24 [00:15<00:15,  1.28s/it]loss: 1.6891, accuracy: 0.7656:  54%|█████▍    | 13/24 [00:16<00:14,  1.30s/it]loss: 1.6073, accuracy: 0.7500:  54%|█████▍    | 13/24 [00:16<00:14,  1.30s/it]loss: 1.6073, accuracy: 0.7500:  58%|█████▊    | 14/24 [00:17<00:13,  1.30s/it]loss: 1.8109, accuracy: 0.7656:  58%|█████▊    | 14/24 [00:17<00:13,  1.30s/it]loss: 1.8109, accuracy: 0.7656:  62%|██████▎   | 15/24 [00:19<00:11,  1.30s/it]loss: 1.7479, accuracy: 0.7656:  62%|██████▎   | 15/24 [00:19<00:11,  1.30s/it]loss: 1.7479, accuracy: 0.7656:  67%|██████▋   | 16/24 [00:20<00:10,  1.28s/it]loss: 1.7551, accuracy: 0.7188:  67%|██████▋   | 16/24 [00:20<00:10,  1.28s/it]loss: 1.7551, accuracy: 0.7188:  71%|███████   | 17/24 [00:21<00:08,  1.28s/it]loss: 1.7266, accuracy: 0.7812:  71%|███████   | 17/24 [00:21<00:08,  1.28s/it]loss: 1.7266, accuracy: 0.7812:  75%|███████▌  | 18/24 [00:23<00:07,  1.28s/it]loss: 1.7934, accuracy: 0.7344:  75%|███████▌  | 18/24 [00:23<00:07,  1.28s/it]loss: 1.7934, accuracy: 0.7344:  79%|███████▉  | 19/24 [00:24<00:06,  1.28s/it]loss: 1.7562, accuracy: 0.7656:  79%|███████▉  | 19/24 [00:24<00:06,  1.28s/it]loss: 1.7562, accuracy: 0.7656:  83%|████████▎ | 20/24 [00:25<00:05,  1.30s/it]loss: 1.7016, accuracy: 0.7344:  83%|████████▎ | 20/24 [00:25<00:05,  1.30s/it]loss: 1.7016, accuracy: 0.7344:  88%|████████▊ | 21/24 [00:26<00:03,  1.29s/it]loss: 2.0052, accuracy: 0.6875:  88%|████████▊ | 21/24 [00:26<00:03,  1.29s/it]loss: 2.0052, accuracy: 0.6875:  92%|█████████▏| 22/24 [00:28<00:02,  1.28s/it]loss: 1.9320, accuracy: 0.7031:  92%|█████████▏| 22/24 [00:28<00:02,  1.28s/it]loss: 1.9320, accuracy: 0.7031:  96%|█████████▌| 23/24 [00:29<00:01,  1.28s/it]loss: 1.8571, accuracy: 0.6875:  96%|█████████▌| 23/24 [00:29<00:01,  1.28s/it]loss: 1.8571, accuracy: 0.6875: 100%|██████████| 24/24 [00:33<00:00,  1.97s/it]loss: 1.6854, accuracy: 0.8148: 100%|██████████| 24/24 [00:33<00:00,  1.97s/it]loss: 1.6854, accuracy: 0.8148: 100%|██████████| 24/24 [00:33<00:00,  1.38s/it]
Epoch 72: epoch_72.0000_train_acc_0.9947_train_loss_1.0204_val_acc_0.7319_val_loss_1.8035 epoch time 169.8173 seconds
  0%|          | 0/71 [00:00<?, ?it/s]  1%|▏         | 1/71 [00:02<02:43,  2.34s/it]loss: 1.0073, accuracy: 1.0000:   1%|▏         | 1/71 [00:02<02:43,  2.34s/it]loss: 1.0073, accuracy: 1.0000:   3%|▎         | 2/71 [00:04<02:19,  2.01s/it]loss: 1.0388, accuracy: 0.9844:   3%|▎         | 2/71 [00:04<02:19,  2.01s/it]loss: 1.0388, accuracy: 0.9844:   4%|▍         | 3/71 [00:05<02:11,  1.93s/it]loss: 1.0051, accuracy: 1.0000:   4%|▍         | 3/71 [00:05<02:11,  1.93s/it]loss: 1.0051, accuracy: 1.0000:   6%|▌         | 4/71 [00:07<02:04,  1.86s/it]loss: 1.0391, accuracy: 0.9844:   6%|▌         | 4/71 [00:07<02:04,  1.86s/it]loss: 1.0391, accuracy: 0.9844:   7%|▋         | 5/71 [00:09<02:00,  1.83s/it]loss: 1.0442, accuracy: 1.0000:   7%|▋         | 5/71 [00:09<02:00,  1.83s/it]loss: 1.0442, accuracy: 1.0000:   8%|▊         | 6/71 [00:11<01:57,  1.82s/it]loss: 0.9937, accuracy: 1.0000:   8%|▊         | 6/71 [00:11<01:57,  1.82s/it]loss: 0.9937, accuracy: 1.0000:  10%|▉         | 7/71 [00:13<01:55,  1.81s/it]loss: 1.0240, accuracy: 1.0000:  10%|▉         | 7/71 [00:13<01:55,  1.81s/it]loss: 1.0240, accuracy: 1.0000:  11%|█▏        | 8/71 [00:14<01:53,  1.81s/it]loss: 0.9899, accuracy: 1.0000:  11%|█▏        | 8/71 [00:14<01:53,  1.81s/it]loss: 0.9899, accuracy: 1.0000:  13%|█▎        | 9/71 [00:16<01:51,  1.80s/it]loss: 0.9912, accuracy: 1.0000:  13%|█▎        | 9/71 [00:16<01:51,  1.80s/it]loss: 0.9912, accuracy: 1.0000:  14%|█▍        | 10/71 [00:18<01:50,  1.81s/it]loss: 1.0378, accuracy: 0.9844:  14%|█▍        | 10/71 [00:18<01:50,  1.81s/it]loss: 1.0378, accuracy: 0.9844:  15%|█▌        | 11/71 [00:20<01:47,  1.79s/it]loss: 1.0505, accuracy: 0.9844:  15%|█▌        | 11/71 [00:20<01:47,  1.79s/it]loss: 1.0505, accuracy: 0.9844:  17%|█▋        | 12/71 [00:22<01:45,  1.78s/it]loss: 1.0115, accuracy: 1.0000:  17%|█▋        | 12/71 [00:22<01:45,  1.78s/it]loss: 1.0115, accuracy: 1.0000:  18%|█▊        | 13/71 [00:23<01:43,  1.78s/it]loss: 1.0832, accuracy: 0.9688:  18%|█▊        | 13/71 [00:23<01:43,  1.78s/it]loss: 1.0832, accuracy: 0.9688:  20%|█▉        | 14/71 [00:25<01:41,  1.78s/it]loss: 1.0630, accuracy: 0.9844:  20%|█▉        | 14/71 [00:25<01:41,  1.78s/it]loss: 1.0630, accuracy: 0.9844:  21%|██        | 15/71 [00:27<01:39,  1.77s/it]loss: 1.0453, accuracy: 0.9844:  21%|██        | 15/71 [00:27<01:39,  1.77s/it]loss: 1.0453, accuracy: 0.9844:  23%|██▎       | 16/71 [00:29<01:37,  1.78s/it]loss: 1.0303, accuracy: 1.0000:  23%|██▎       | 16/71 [00:29<01:37,  1.78s/it]loss: 1.0303, accuracy: 1.0000:  24%|██▍       | 17/71 [00:30<01:37,  1.80s/it]loss: 1.0275, accuracy: 1.0000:  24%|██▍       | 17/71 [00:30<01:37,  1.80s/it]loss: 1.0275, accuracy: 1.0000:  25%|██▌       | 18/71 [00:32<01:34,  1.79s/it]loss: 0.9907, accuracy: 1.0000:  25%|██▌       | 18/71 [00:32<01:34,  1.79s/it]loss: 0.9907, accuracy: 1.0000:  27%|██▋       | 19/71 [00:34<01:32,  1.78s/it]loss: 0.9872, accuracy: 1.0000:  27%|██▋       | 19/71 [00:34<01:32,  1.78s/it]loss: 0.9872, accuracy: 1.0000:  28%|██▊       | 20/71 [00:36<01:30,  1.78s/it]loss: 1.0159, accuracy: 1.0000:  28%|██▊       | 20/71 [00:36<01:30,  1.78s/it]loss: 1.0159, accuracy: 1.0000:  30%|██▉       | 21/71 [00:37<01:28,  1.77s/it]loss: 0.9892, accuracy: 1.0000:  30%|██▉       | 21/71 [00:37<01:28,  1.77s/it]loss: 0.9892, accuracy: 1.0000:  31%|███       | 22/71 [00:39<01:26,  1.76s/it]loss: 1.0196, accuracy: 1.0000:  31%|███       | 22/71 [00:39<01:26,  1.76s/it]loss: 1.0196, accuracy: 1.0000:  32%|███▏      | 23/71 [00:41<01:25,  1.78s/it]loss: 1.0502, accuracy: 0.9844:  32%|███▏      | 23/71 [00:41<01:25,  1.78s/it]loss: 1.0502, accuracy: 0.9844:  34%|███▍      | 24/71 [00:43<01:23,  1.78s/it]loss: 1.0619, accuracy: 0.9844:  34%|███▍      | 24/71 [00:43<01:23,  1.78s/it]loss: 1.0619, accuracy: 0.9844:  35%|███▌      | 25/71 [00:45<01:21,  1.78s/it]loss: 1.0033, accuracy: 1.0000:  35%|███▌      | 25/71 [00:45<01:21,  1.78s/it]loss: 1.0033, accuracy: 1.0000:  37%|███▋      | 26/71 [00:46<01:20,  1.78s/it]loss: 1.0390, accuracy: 0.9844:  37%|███▋      | 26/71 [00:46<01:20,  1.78s/it]loss: 1.0390, accuracy: 0.9844:  38%|███▊      | 27/71 [00:48<01:18,  1.77s/it]loss: 1.0184, accuracy: 0.9844:  38%|███▊      | 27/71 [00:48<01:18,  1.77s/it]loss: 1.0184, accuracy: 0.9844:  39%|███▉      | 28/71 [00:50<01:15,  1.77s/it]loss: 1.0116, accuracy: 1.0000:  39%|███▉      | 28/71 [00:50<01:15,  1.77s/it]loss: 1.0116, accuracy: 1.0000:  41%|████      | 29/71 [00:52<01:14,  1.76s/it]loss: 0.9974, accuracy: 1.0000:  41%|████      | 29/71 [00:52<01:14,  1.76s/it]loss: 0.9974, accuracy: 1.0000:  42%|████▏     | 30/71 [00:53<01:12,  1.78s/it]loss: 1.0529, accuracy: 0.9844:  42%|████▏     | 30/71 [00:53<01:12,  1.78s/it]loss: 1.0529, accuracy: 0.9844:  44%|████▎     | 31/71 [00:55<01:10,  1.77s/it]loss: 1.0259, accuracy: 1.0000:  44%|████▎     | 31/71 [00:55<01:10,  1.77s/it]loss: 1.0259, accuracy: 1.0000:  45%|████▌     | 32/71 [00:57<01:08,  1.76s/it]loss: 1.0219, accuracy: 1.0000:  45%|████▌     | 32/71 [00:57<01:08,  1.76s/it]loss: 1.0219, accuracy: 1.0000:  46%|████▋     | 33/71 [00:59<01:07,  1.77s/it]loss: 1.0436, accuracy: 0.9844:  46%|████▋     | 33/71 [00:59<01:07,  1.77s/it]loss: 1.0436, accuracy: 0.9844:  48%|████▊     | 34/71 [01:01<01:05,  1.77s/it]loss: 1.0052, accuracy: 1.0000:  48%|████▊     | 34/71 [01:01<01:05,  1.77s/it]loss: 1.0052, accuracy: 1.0000:  49%|████▉     | 35/71 [01:02<01:03,  1.77s/it]loss: 1.0092, accuracy: 1.0000:  49%|████▉     | 35/71 [01:02<01:03,  1.77s/it]loss: 1.0092, accuracy: 1.0000:  51%|█████     | 36/71 [01:04<01:01,  1.77s/it]loss: 1.0106, accuracy: 1.0000:  51%|█████     | 36/71 [01:04<01:01,  1.77s/it]loss: 1.0106, accuracy: 1.0000:  52%|█████▏    | 37/71 [01:06<01:00,  1.79s/it]loss: 1.0349, accuracy: 1.0000:  52%|█████▏    | 37/71 [01:06<01:00,  1.79s/it]loss: 1.0349, accuracy: 1.0000:  54%|█████▎    | 38/71 [01:08<00:58,  1.78s/it]loss: 1.0048, accuracy: 1.0000:  54%|█████▎    | 38/71 [01:08<00:58,  1.78s/it]loss: 1.0048, accuracy: 1.0000:  55%|█████▍    | 39/71 [01:09<00:56,  1.77s/it]loss: 1.0430, accuracy: 1.0000:  55%|█████▍    | 39/71 [01:09<00:56,  1.77s/it]loss: 1.0430, accuracy: 1.0000:  56%|█████▋    | 40/71 [01:11<00:54,  1.77s/it]loss: 1.0259, accuracy: 0.9844:  56%|█████▋    | 40/71 [01:11<00:54,  1.77s/it]loss: 1.0259, accuracy: 0.9844:  58%|█████▊    | 41/71 [01:13<00:53,  1.77s/it]loss: 1.0367, accuracy: 0.9844:  58%|█████▊    | 41/71 [01:13<00:53,  1.77s/it]loss: 1.0367, accuracy: 0.9844:  59%|█████▉    | 42/71 [01:15<00:51,  1.78s/it]loss: 1.0363, accuracy: 1.0000:  59%|█████▉    | 42/71 [01:15<00:51,  1.78s/it]loss: 1.0363, accuracy: 1.0000:  61%|██████    | 43/71 [01:17<00:49,  1.77s/it]loss: 1.0144, accuracy: 1.0000:  61%|██████    | 43/71 [01:17<00:49,  1.77s/it]loss: 1.0144, accuracy: 1.0000:  62%|██████▏   | 44/71 [01:18<00:48,  1.80s/it]loss: 1.0541, accuracy: 0.9688:  62%|██████▏   | 44/71 [01:18<00:48,  1.80s/it]loss: 1.0541, accuracy: 0.9688:  63%|██████▎   | 45/71 [01:20<00:46,  1.79s/it]loss: 1.0722, accuracy: 0.9844:  63%|██████▎   | 45/71 [01:20<00:46,  1.79s/it]loss: 1.0722, accuracy: 0.9844:  65%|██████▍   | 46/71 [01:22<00:44,  1.79s/it]loss: 1.0282, accuracy: 0.9844:  65%|██████▍   | 46/71 [01:22<00:44,  1.79s/it]loss: 1.0282, accuracy: 0.9844:  66%|██████▌   | 47/71 [01:24<00:42,  1.78s/it]loss: 1.0245, accuracy: 1.0000:  66%|██████▌   | 47/71 [01:24<00:42,  1.78s/it]loss: 1.0245, accuracy: 1.0000:  68%|██████▊   | 48/71 [01:25<00:40,  1.78s/it]loss: 1.0090, accuracy: 0.9844:  68%|██████▊   | 48/71 [01:25<00:40,  1.78s/it]loss: 1.0090, accuracy: 0.9844:  69%|██████▉   | 49/71 [01:27<00:39,  1.78s/it]loss: 1.0404, accuracy: 0.9688:  69%|██████▉   | 49/71 [01:27<00:39,  1.78s/it]loss: 1.0404, accuracy: 0.9688:  70%|███████   | 50/71 [01:29<00:37,  1.78s/it]loss: 1.0332, accuracy: 0.9844:  70%|███████   | 50/71 [01:29<00:37,  1.78s/it]loss: 1.0332, accuracy: 0.9844:  72%|███████▏  | 51/71 [01:31<00:35,  1.78s/it]loss: 1.0135, accuracy: 1.0000:  72%|███████▏  | 51/71 [01:31<00:35,  1.78s/it]loss: 1.0135, accuracy: 1.0000:  73%|███████▎  | 52/71 [01:33<00:33,  1.77s/it]loss: 1.0805, accuracy: 0.9844:  73%|███████▎  | 52/71 [01:33<00:33,  1.77s/it]loss: 1.0805, accuracy: 0.9844:  75%|███████▍  | 53/71 [01:34<00:31,  1.76s/it]loss: 1.0309, accuracy: 1.0000:  75%|███████▍  | 53/71 [01:34<00:31,  1.76s/it]loss: 1.0309, accuracy: 1.0000:  76%|███████▌  | 54/71 [01:36<00:30,  1.77s/it]loss: 1.0326, accuracy: 1.0000:  76%|███████▌  | 54/71 [01:36<00:30,  1.77s/it]loss: 1.0326, accuracy: 1.0000:  77%|███████▋  | 55/71 [01:38<00:28,  1.77s/it]loss: 1.0537, accuracy: 0.9844:  77%|███████▋  | 55/71 [01:38<00:28,  1.77s/it]loss: 1.0537, accuracy: 0.9844:  79%|███████▉  | 56/71 [01:40<00:26,  1.77s/it]loss: 1.0401, accuracy: 0.9844:  79%|███████▉  | 56/71 [01:40<00:26,  1.77s/it]loss: 1.0401, accuracy: 0.9844:  80%|████████  | 57/71 [01:41<00:24,  1.77s/it]loss: 1.0248, accuracy: 1.0000:  80%|████████  | 57/71 [01:41<00:24,  1.77s/it]loss: 1.0248, accuracy: 1.0000:  82%|████████▏ | 58/71 [01:43<00:23,  1.78s/it]loss: 1.0054, accuracy: 1.0000:  82%|████████▏ | 58/71 [01:43<00:23,  1.78s/it]loss: 1.0054, accuracy: 1.0000:  83%|████████▎ | 59/71 [01:45<00:21,  1.78s/it]loss: 1.0261, accuracy: 1.0000:  83%|████████▎ | 59/71 [01:45<00:21,  1.78s/it]loss: 1.0261, accuracy: 1.0000:  85%|████████▍ | 60/71 [01:47<00:19,  1.77s/it]loss: 1.0419, accuracy: 1.0000:  85%|████████▍ | 60/71 [01:47<00:19,  1.77s/it]loss: 1.0419, accuracy: 1.0000:  86%|████████▌ | 61/71 [01:48<00:17,  1.77s/it]loss: 1.0234, accuracy: 1.0000:  86%|████████▌ | 61/71 [01:48<00:17,  1.77s/it]loss: 1.0234, accuracy: 1.0000:  87%|████████▋ | 62/71 [01:50<00:15,  1.76s/it]loss: 1.0182, accuracy: 1.0000:  87%|████████▋ | 62/71 [01:50<00:15,  1.76s/it]loss: 1.0182, accuracy: 1.0000:  89%|████████▊ | 63/71 [01:52<00:14,  1.76s/it]loss: 1.0169, accuracy: 0.9844:  89%|████████▊ | 63/71 [01:52<00:14,  1.76s/it]loss: 1.0169, accuracy: 0.9844:  90%|█████████ | 64/71 [01:54<00:12,  1.76s/it]loss: 1.0268, accuracy: 1.0000:  90%|█████████ | 64/71 [01:54<00:12,  1.76s/it]loss: 1.0268, accuracy: 1.0000:  92%|█████████▏| 65/71 [01:56<00:10,  1.80s/it]loss: 1.0205, accuracy: 1.0000:  92%|█████████▏| 65/71 [01:56<00:10,  1.80s/it]loss: 1.0205, accuracy: 1.0000:  93%|█████████▎| 66/71 [01:57<00:08,  1.80s/it]loss: 1.0284, accuracy: 0.9844:  93%|█████████▎| 66/71 [01:57<00:08,  1.80s/it]loss: 1.0284, accuracy: 0.9844:  94%|█████████▍| 67/71 [01:59<00:07,  1.78s/it]loss: 1.0075, accuracy: 1.0000:  94%|█████████▍| 67/71 [01:59<00:07,  1.78s/it]loss: 1.0075, accuracy: 1.0000:  96%|█████████▌| 68/71 [02:01<00:05,  1.77s/it]loss: 1.0432, accuracy: 1.0000:  96%|█████████▌| 68/71 [02:01<00:05,  1.77s/it]loss: 1.0432, accuracy: 1.0000:  97%|█████████▋| 69/71 [02:03<00:03,  1.77s/it]loss: 1.0382, accuracy: 0.9688:  97%|█████████▋| 69/71 [02:03<00:03,  1.77s/it]loss: 1.0382, accuracy: 0.9688:  99%|█████████▊| 70/71 [02:04<00:01,  1.77s/it]loss: 1.0123, accuracy: 1.0000:  99%|█████████▊| 70/71 [02:04<00:01,  1.77s/it]loss: 1.0123, accuracy: 1.0000: 100%|██████████| 71/71 [02:05<00:00,  1.50s/it]loss: 0.9446, accuracy: 1.0000: 100%|██████████| 71/71 [02:05<00:00,  1.50s/it]loss: 0.9446, accuracy: 1.0000: 100%|██████████| 71/71 [02:05<00:00,  1.77s/it]
  0%|          | 0/24 [00:00<?, ?it/s]  4%|▍         | 1/24 [00:01<00:29,  1.27s/it]loss: 1.7128, accuracy: 0.7656:   4%|▍         | 1/24 [00:01<00:29,  1.27s/it]loss: 1.7128, accuracy: 0.7656:   8%|▊         | 2/24 [00:02<00:26,  1.23s/it]loss: 1.8461, accuracy: 0.7188:   8%|▊         | 2/24 [00:02<00:26,  1.23s/it]loss: 1.8461, accuracy: 0.7188:  12%|█▎        | 3/24 [00:03<00:25,  1.22s/it]loss: 2.0590, accuracy: 0.6406:  12%|█▎        | 3/24 [00:03<00:25,  1.22s/it]loss: 2.0590, accuracy: 0.6406:  17%|█▋        | 4/24 [00:04<00:24,  1.22s/it]loss: 1.6384, accuracy: 0.7969:  17%|█▋        | 4/24 [00:04<00:24,  1.22s/it]loss: 1.6384, accuracy: 0.7969:  21%|██        | 5/24 [00:06<00:23,  1.22s/it]loss: 1.6806, accuracy: 0.7500:  21%|██        | 5/24 [00:06<00:23,  1.22s/it]loss: 1.6806, accuracy: 0.7500:  25%|██▌       | 6/24 [00:07<00:21,  1.21s/it]loss: 1.3893, accuracy: 0.8906:  25%|██▌       | 6/24 [00:07<00:21,  1.21s/it]loss: 1.3893, accuracy: 0.8906:  29%|██▉       | 7/24 [00:08<00:20,  1.22s/it]loss: 1.7643, accuracy: 0.7812:  29%|██▉       | 7/24 [00:08<00:20,  1.22s/it]loss: 1.7643, accuracy: 0.7812:  33%|███▎      | 8/24 [00:09<00:19,  1.24s/it]loss: 1.7255, accuracy: 0.7812:  33%|███▎      | 8/24 [00:09<00:19,  1.24s/it]loss: 1.7255, accuracy: 0.7812:  38%|███▊      | 9/24 [00:11<00:18,  1.23s/it]loss: 1.7542, accuracy: 0.7344:  38%|███▊      | 9/24 [00:11<00:18,  1.23s/it]loss: 1.7542, accuracy: 0.7344:  42%|████▏     | 10/24 [00:12<00:17,  1.22s/it]loss: 1.9044, accuracy: 0.7344:  42%|████▏     | 10/24 [00:12<00:17,  1.22s/it]loss: 1.9044, accuracy: 0.7344:  46%|████▌     | 11/24 [00:13<00:15,  1.22s/it]loss: 2.0508, accuracy: 0.6875:  46%|████▌     | 11/24 [00:13<00:15,  1.22s/it]loss: 2.0508, accuracy: 0.6875:  50%|█████     | 12/24 [00:14<00:14,  1.22s/it]loss: 1.7104, accuracy: 0.7188:  50%|█████     | 12/24 [00:14<00:14,  1.22s/it]loss: 1.7104, accuracy: 0.7188:  54%|█████▍    | 13/24 [00:15<00:13,  1.22s/it]loss: 1.6416, accuracy: 0.7812:  54%|█████▍    | 13/24 [00:15<00:13,  1.22s/it]loss: 1.6416, accuracy: 0.7812:  58%|█████▊    | 14/24 [00:17<00:12,  1.22s/it]loss: 1.9051, accuracy: 0.7188:  58%|█████▊    | 14/24 [00:17<00:12,  1.22s/it]loss: 1.9051, accuracy: 0.7188:  62%|██████▎   | 15/24 [00:18<00:11,  1.22s/it]loss: 1.9398, accuracy: 0.6875:  62%|██████▎   | 15/24 [00:18<00:11,  1.22s/it]loss: 1.9398, accuracy: 0.6875:  67%|██████▋   | 16/24 [00:19<00:09,  1.25s/it]loss: 1.8894, accuracy: 0.7031:  67%|██████▋   | 16/24 [00:19<00:09,  1.25s/it]loss: 1.8894, accuracy: 0.7031:  71%|███████   | 17/24 [00:20<00:08,  1.24s/it]loss: 1.8069, accuracy: 0.6719:  71%|███████   | 17/24 [00:20<00:08,  1.24s/it]loss: 1.8069, accuracy: 0.6719:  75%|███████▌  | 18/24 [00:22<00:07,  1.24s/it]loss: 1.6904, accuracy: 0.7500:  75%|███████▌  | 18/24 [00:22<00:07,  1.24s/it]loss: 1.6904, accuracy: 0.7500:  79%|███████▉  | 19/24 [00:23<00:06,  1.22s/it]loss: 1.6638, accuracy: 0.7969:  79%|███████▉  | 19/24 [00:23<00:06,  1.22s/it]loss: 1.6638, accuracy: 0.7969:  83%|████████▎ | 20/24 [00:24<00:04,  1.22s/it]loss: 1.9315, accuracy: 0.7344:  83%|████████▎ | 20/24 [00:24<00:04,  1.22s/it]loss: 1.9315, accuracy: 0.7344:  88%|████████▊ | 21/24 [00:25<00:03,  1.21s/it]loss: 1.9136, accuracy: 0.6719:  88%|████████▊ | 21/24 [00:25<00:03,  1.21s/it]loss: 1.9136, accuracy: 0.6719:  92%|█████████▏| 22/24 [00:27<00:02,  1.24s/it]loss: 1.7720, accuracy: 0.7188:  92%|█████████▏| 22/24 [00:27<00:02,  1.24s/it]loss: 1.7720, accuracy: 0.7188:  96%|█████████▌| 23/24 [00:28<00:01,  1.25s/it]loss: 1.7853, accuracy: 0.7031:  96%|█████████▌| 23/24 [00:28<00:01,  1.25s/it]loss: 1.7853, accuracy: 0.7031: 100%|██████████| 24/24 [00:28<00:00,  1.07s/it]loss: 1.6087, accuracy: 0.7407: 100%|██████████| 24/24 [00:28<00:00,  1.07s/it]loss: 1.6087, accuracy: 0.7407: 100%|██████████| 24/24 [00:28<00:00,  1.21s/it]
Epoch 73: epoch_73.0000_train_acc_0.9932_train_loss_1.0257_val_acc_0.7366_val_loss_1.7827 epoch time 154.7689 seconds
Traceback (most recent call last):
  File "/home/s2016765/miniconda3/envs/mlp/lib/python3.12/site-packages/torch/serialization.py", line 629, in save
    _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)
  File "/home/s2016765/miniconda3/envs/mlp/lib/python3.12/site-packages/torch/serialization.py", line 863, in _save
    zip_file.write_record(name, storage.data_ptr(), num_bytes)
RuntimeError: [enforce fail at inline_container.cc:764] . PytorchStreamWriter failed writing file data/61: file write failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/s2016765/final_project/train_models.py", line 159, in <module>
    experiment_metrics, test_metrics = conv_experiment.run_experiment()  # run experiment and return experiment metrics
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/s2016765/final_project/pytorch_mlp_framework/experiment_builder.py", line 294, in run_experiment
    self.save_model(model_save_dir=self.experiment_saved_models,
  File "/home/s2016765/final_project/pytorch_mlp_framework/experiment_builder.py", line 232, in save_model
    torch.save(self.state, f=os.path.join(model_save_dir, "{}_{}".format(model_save_name, str(
  File "/home/s2016765/miniconda3/envs/mlp/lib/python3.12/site-packages/torch/serialization.py", line 628, in save
    with _open_zipfile_writer(f) as opened_zipfile:
  File "/home/s2016765/miniconda3/envs/mlp/lib/python3.12/site-packages/torch/serialization.py", line 476, in __exit__
    self.file_like.write_end_of_file()
RuntimeError: [enforce fail at inline_container.cc:595] . unexpected pos 237468928 vs 237468816
