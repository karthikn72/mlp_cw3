Namespace(batch_size=64, continue_from_epoch=23, seed=0, num_epochs=77, experiment_name='vitb16_aircraft_224_224', use_gpu=True, weight_decay_coefficient=0.0005, learning_rate=0.001, model='vitb16', pretrain='imagenet', dataloader='aircrafts', height=224, width=224)
Number of training samples:  3334
Number of validation samples:  3333
Number of testing samples:  3333
Number of classes: 100
Use Multi GPU 0
here
System learnable parameters
model.module.class_token torch.Size([1, 1, 768])
model.module.conv_proj.weight torch.Size([768, 3, 16, 16])
model.module.conv_proj.bias torch.Size([768])
model.module.encoder.pos_embedding torch.Size([1, 197, 768])
model.module.encoder.layers.encoder_layer_0.ln_1.weight torch.Size([768])
model.module.encoder.layers.encoder_layer_0.ln_1.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_0.self_attention.in_proj_weight torch.Size([2304, 768])
model.module.encoder.layers.encoder_layer_0.self_attention.in_proj_bias torch.Size([2304])
model.module.encoder.layers.encoder_layer_0.self_attention.out_proj.weight torch.Size([768, 768])
model.module.encoder.layers.encoder_layer_0.self_attention.out_proj.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_0.ln_2.weight torch.Size([768])
model.module.encoder.layers.encoder_layer_0.ln_2.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_0.mlp.0.weight torch.Size([3072, 768])
model.module.encoder.layers.encoder_layer_0.mlp.0.bias torch.Size([3072])
model.module.encoder.layers.encoder_layer_0.mlp.3.weight torch.Size([768, 3072])
model.module.encoder.layers.encoder_layer_0.mlp.3.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_1.ln_1.weight torch.Size([768])
model.module.encoder.layers.encoder_layer_1.ln_1.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_1.self_attention.in_proj_weight torch.Size([2304, 768])
model.module.encoder.layers.encoder_layer_1.self_attention.in_proj_bias torch.Size([2304])
model.module.encoder.layers.encoder_layer_1.self_attention.out_proj.weight torch.Size([768, 768])
model.module.encoder.layers.encoder_layer_1.self_attention.out_proj.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_1.ln_2.weight torch.Size([768])
model.module.encoder.layers.encoder_layer_1.ln_2.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_1.mlp.0.weight torch.Size([3072, 768])
model.module.encoder.layers.encoder_layer_1.mlp.0.bias torch.Size([3072])
model.module.encoder.layers.encoder_layer_1.mlp.3.weight torch.Size([768, 3072])
model.module.encoder.layers.encoder_layer_1.mlp.3.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_2.ln_1.weight torch.Size([768])
model.module.encoder.layers.encoder_layer_2.ln_1.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_2.self_attention.in_proj_weight torch.Size([2304, 768])
model.module.encoder.layers.encoder_layer_2.self_attention.in_proj_bias torch.Size([2304])
model.module.encoder.layers.encoder_layer_2.self_attention.out_proj.weight torch.Size([768, 768])
model.module.encoder.layers.encoder_layer_2.self_attention.out_proj.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_2.ln_2.weight torch.Size([768])
model.module.encoder.layers.encoder_layer_2.ln_2.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_2.mlp.0.weight torch.Size([3072, 768])
model.module.encoder.layers.encoder_layer_2.mlp.0.bias torch.Size([3072])
model.module.encoder.layers.encoder_layer_2.mlp.3.weight torch.Size([768, 3072])
model.module.encoder.layers.encoder_layer_2.mlp.3.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_3.ln_1.weight torch.Size([768])
model.module.encoder.layers.encoder_layer_3.ln_1.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_3.self_attention.in_proj_weight torch.Size([2304, 768])
model.module.encoder.layers.encoder_layer_3.self_attention.in_proj_bias torch.Size([2304])
model.module.encoder.layers.encoder_layer_3.self_attention.out_proj.weight torch.Size([768, 768])
model.module.encoder.layers.encoder_layer_3.self_attention.out_proj.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_3.ln_2.weight torch.Size([768])
model.module.encoder.layers.encoder_layer_3.ln_2.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_3.mlp.0.weight torch.Size([3072, 768])
model.module.encoder.layers.encoder_layer_3.mlp.0.bias torch.Size([3072])
model.module.encoder.layers.encoder_layer_3.mlp.3.weight torch.Size([768, 3072])
model.module.encoder.layers.encoder_layer_3.mlp.3.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_4.ln_1.weight torch.Size([768])
model.module.encoder.layers.encoder_layer_4.ln_1.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_4.self_attention.in_proj_weight torch.Size([2304, 768])
model.module.encoder.layers.encoder_layer_4.self_attention.in_proj_bias torch.Size([2304])
model.module.encoder.layers.encoder_layer_4.self_attention.out_proj.weight torch.Size([768, 768])
model.module.encoder.layers.encoder_layer_4.self_attention.out_proj.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_4.ln_2.weight torch.Size([768])
model.module.encoder.layers.encoder_layer_4.ln_2.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_4.mlp.0.weight torch.Size([3072, 768])
model.module.encoder.layers.encoder_layer_4.mlp.0.bias torch.Size([3072])
model.module.encoder.layers.encoder_layer_4.mlp.3.weight torch.Size([768, 3072])
model.module.encoder.layers.encoder_layer_4.mlp.3.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_5.ln_1.weight torch.Size([768])
model.module.encoder.layers.encoder_layer_5.ln_1.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_5.self_attention.in_proj_weight torch.Size([2304, 768])
model.module.encoder.layers.encoder_layer_5.self_attention.in_proj_bias torch.Size([2304])
model.module.encoder.layers.encoder_layer_5.self_attention.out_proj.weight torch.Size([768, 768])
model.module.encoder.layers.encoder_layer_5.self_attention.out_proj.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_5.ln_2.weight torch.Size([768])
model.module.encoder.layers.encoder_layer_5.ln_2.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_5.mlp.0.weight torch.Size([3072, 768])
model.module.encoder.layers.encoder_layer_5.mlp.0.bias torch.Size([3072])
model.module.encoder.layers.encoder_layer_5.mlp.3.weight torch.Size([768, 3072])
model.module.encoder.layers.encoder_layer_5.mlp.3.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_6.ln_1.weight torch.Size([768])
model.module.encoder.layers.encoder_layer_6.ln_1.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_6.self_attention.in_proj_weight torch.Size([2304, 768])
model.module.encoder.layers.encoder_layer_6.self_attention.in_proj_bias torch.Size([2304])
model.module.encoder.layers.encoder_layer_6.self_attention.out_proj.weight torch.Size([768, 768])
model.module.encoder.layers.encoder_layer_6.self_attention.out_proj.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_6.ln_2.weight torch.Size([768])
model.module.encoder.layers.encoder_layer_6.ln_2.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_6.mlp.0.weight torch.Size([3072, 768])
model.module.encoder.layers.encoder_layer_6.mlp.0.bias torch.Size([3072])
model.module.encoder.layers.encoder_layer_6.mlp.3.weight torch.Size([768, 3072])
model.module.encoder.layers.encoder_layer_6.mlp.3.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_7.ln_1.weight torch.Size([768])
model.module.encoder.layers.encoder_layer_7.ln_1.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_7.self_attention.in_proj_weight torch.Size([2304, 768])
model.module.encoder.layers.encoder_layer_7.self_attention.in_proj_bias torch.Size([2304])
model.module.encoder.layers.encoder_layer_7.self_attention.out_proj.weight torch.Size([768, 768])
model.module.encoder.layers.encoder_layer_7.self_attention.out_proj.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_7.ln_2.weight torch.Size([768])
model.module.encoder.layers.encoder_layer_7.ln_2.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_7.mlp.0.weight torch.Size([3072, 768])
model.module.encoder.layers.encoder_layer_7.mlp.0.bias torch.Size([3072])
model.module.encoder.layers.encoder_layer_7.mlp.3.weight torch.Size([768, 3072])
model.module.encoder.layers.encoder_layer_7.mlp.3.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_8.ln_1.weight torch.Size([768])
model.module.encoder.layers.encoder_layer_8.ln_1.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_8.self_attention.in_proj_weight torch.Size([2304, 768])
model.module.encoder.layers.encoder_layer_8.self_attention.in_proj_bias torch.Size([2304])
model.module.encoder.layers.encoder_layer_8.self_attention.out_proj.weight torch.Size([768, 768])
model.module.encoder.layers.encoder_layer_8.self_attention.out_proj.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_8.ln_2.weight torch.Size([768])
model.module.encoder.layers.encoder_layer_8.ln_2.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_8.mlp.0.weight torch.Size([3072, 768])
model.module.encoder.layers.encoder_layer_8.mlp.0.bias torch.Size([3072])
model.module.encoder.layers.encoder_layer_8.mlp.3.weight torch.Size([768, 3072])
model.module.encoder.layers.encoder_layer_8.mlp.3.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_9.ln_1.weight torch.Size([768])
model.module.encoder.layers.encoder_layer_9.ln_1.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_9.self_attention.in_proj_weight torch.Size([2304, 768])
model.module.encoder.layers.encoder_layer_9.self_attention.in_proj_bias torch.Size([2304])
model.module.encoder.layers.encoder_layer_9.self_attention.out_proj.weight torch.Size([768, 768])
model.module.encoder.layers.encoder_layer_9.self_attention.out_proj.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_9.ln_2.weight torch.Size([768])
model.module.encoder.layers.encoder_layer_9.ln_2.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_9.mlp.0.weight torch.Size([3072, 768])
model.module.encoder.layers.encoder_layer_9.mlp.0.bias torch.Size([3072])
model.module.encoder.layers.encoder_layer_9.mlp.3.weight torch.Size([768, 3072])
model.module.encoder.layers.encoder_layer_9.mlp.3.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_10.ln_1.weight torch.Size([768])
model.module.encoder.layers.encoder_layer_10.ln_1.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_10.self_attention.in_proj_weight torch.Size([2304, 768])
model.module.encoder.layers.encoder_layer_10.self_attention.in_proj_bias torch.Size([2304])
model.module.encoder.layers.encoder_layer_10.self_attention.out_proj.weight torch.Size([768, 768])
model.module.encoder.layers.encoder_layer_10.self_attention.out_proj.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_10.ln_2.weight torch.Size([768])
model.module.encoder.layers.encoder_layer_10.ln_2.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_10.mlp.0.weight torch.Size([3072, 768])
model.module.encoder.layers.encoder_layer_10.mlp.0.bias torch.Size([3072])
model.module.encoder.layers.encoder_layer_10.mlp.3.weight torch.Size([768, 3072])
model.module.encoder.layers.encoder_layer_10.mlp.3.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_11.ln_1.weight torch.Size([768])
model.module.encoder.layers.encoder_layer_11.ln_1.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_11.self_attention.in_proj_weight torch.Size([2304, 768])
model.module.encoder.layers.encoder_layer_11.self_attention.in_proj_bias torch.Size([2304])
model.module.encoder.layers.encoder_layer_11.self_attention.out_proj.weight torch.Size([768, 768])
model.module.encoder.layers.encoder_layer_11.self_attention.out_proj.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_11.ln_2.weight torch.Size([768])
model.module.encoder.layers.encoder_layer_11.ln_2.bias torch.Size([768])
model.module.encoder.layers.encoder_layer_11.mlp.0.weight torch.Size([3072, 768])
model.module.encoder.layers.encoder_layer_11.mlp.0.bias torch.Size([3072])
model.module.encoder.layers.encoder_layer_11.mlp.3.weight torch.Size([768, 3072])
model.module.encoder.layers.encoder_layer_11.mlp.3.bias torch.Size([768])
model.module.encoder.ln.weight torch.Size([768])
model.module.encoder.ln.bias torch.Size([768])
model.module.heads.head.weight torch.Size([1000, 768])
model.module.heads.head.bias torch.Size([1000])
Total number of parameters 86567656
Total number of conv layers 1
Total number of linear layers 0
  0%|          | 0/53 [00:00<?, ?it/s]  2%|▏         | 1/53 [00:32<27:48, 32.09s/it]loss: 3.1421, accuracy: 0.5000:   2%|▏         | 1/53 [00:32<27:48, 32.09s/it]loss: 3.1421, accuracy: 0.5000:   4%|▍         | 2/53 [00:46<18:13, 21.43s/it]loss: 3.2261, accuracy: 0.3906:   4%|▍         | 2/53 [00:46<18:13, 21.43s/it]loss: 3.2261, accuracy: 0.3906:   6%|▌         | 3/53 [01:00<15:07, 18.14s/it]loss: 3.2117, accuracy: 0.3750:   6%|▌         | 3/53 [01:00<15:07, 18.14s/it]loss: 3.2117, accuracy: 0.3750:   8%|▊         | 4/53 [01:14<13:30, 16.54s/it]loss: 3.3662, accuracy: 0.3906:   8%|▊         | 4/53 [01:14<13:30, 16.54s/it]loss: 3.3662, accuracy: 0.3906:   9%|▉         | 5/53 [01:28<12:28, 15.59s/it]loss: 3.2337, accuracy: 0.4219:   9%|▉         | 5/53 [01:28<12:28, 15.59s/it]loss: 3.2337, accuracy: 0.4219:  11%|█▏        | 6/53 [01:42<11:48, 15.07s/it]loss: 3.1432, accuracy: 0.4531:  11%|█▏        | 6/53 [01:42<11:48, 15.07s/it]loss: 3.1432, accuracy: 0.4531:  13%|█▎        | 7/53 [01:56<11:12, 14.63s/it]loss: 3.0463, accuracy: 0.3906:  13%|█▎        | 7/53 [01:56<11:12, 14.63s/it]loss: 3.0463, accuracy: 0.3906:  15%|█▌        | 8/53 [02:10<10:53, 14.53s/it]loss: 3.2847, accuracy: 0.4688:  15%|█▌        | 8/53 [02:10<10:53, 14.53s/it]loss: 3.2847, accuracy: 0.4688:  17%|█▋        | 9/53 [02:24<10:32, 14.39s/it]loss: 3.3484, accuracy: 0.3281:  17%|█▋        | 9/53 [02:24<10:32, 14.39s/it]loss: 3.3484, accuracy: 0.3281:  19%|█▉        | 10/53 [02:38<10:10, 14.20s/it]loss: 2.7915, accuracy: 0.5000:  19%|█▉        | 10/53 [02:38<10:10, 14.20s/it]loss: 2.7915, accuracy: 0.5000:  21%|██        | 11/53 [02:52<09:53, 14.13s/it]loss: 3.1721, accuracy: 0.4531:  21%|██        | 11/53 [02:52<09:53, 14.13s/it]loss: 3.1721, accuracy: 0.4531:  23%|██▎       | 12/53 [03:06<09:35, 14.05s/it]loss: 3.2133, accuracy: 0.4062:  23%|██▎       | 12/53 [03:06<09:35, 14.05s/it]loss: 3.2133, accuracy: 0.4062:  25%|██▍       | 13/53 [03:20<09:20, 14.02s/it]loss: 3.2574, accuracy: 0.3594:  25%|██▍       | 13/53 [03:20<09:20, 14.02s/it]loss: 3.2574, accuracy: 0.3594:  26%|██▋       | 14/53 [03:34<09:07, 14.04s/it]loss: 3.0497, accuracy: 0.4062:  26%|██▋       | 14/53 [03:34<09:07, 14.04s/it]loss: 3.0497, accuracy: 0.4062:  28%|██▊       | 15/53 [03:48<08:54, 14.06s/it]loss: 3.1683, accuracy: 0.4688:  28%|██▊       | 15/53 [03:48<08:54, 14.06s/it]loss: 3.1683, accuracy: 0.4688:  30%|███       | 16/53 [04:02<08:38, 14.02s/it]loss: 3.4493, accuracy: 0.3438:  30%|███       | 16/53 [04:02<08:38, 14.02s/it]loss: 3.4493, accuracy: 0.3438:  32%|███▏      | 17/53 [04:16<08:24, 14.02s/it]loss: 3.1173, accuracy: 0.4375:  32%|███▏      | 17/53 [04:16<08:24, 14.02s/it]loss: 3.1173, accuracy: 0.4375:  34%|███▍      | 18/53 [04:30<08:09, 13.98s/it]loss: 3.3621, accuracy: 0.3438:  34%|███▍      | 18/53 [04:30<08:09, 13.98s/it]loss: 3.3621, accuracy: 0.3438:  36%|███▌      | 19/53 [04:44<07:56, 14.01s/it]loss: 3.2612, accuracy: 0.4062:  36%|███▌      | 19/53 [04:44<07:56, 14.01s/it]loss: 3.2612, accuracy: 0.4062:  38%|███▊      | 20/53 [04:58<07:41, 14.00s/it]loss: 3.3832, accuracy: 0.3281:  38%|███▊      | 20/53 [04:58<07:41, 14.00s/it]loss: 3.3832, accuracy: 0.3281:  40%|███▉      | 21/53 [05:12<07:30, 14.09s/it]loss: 3.3145, accuracy: 0.4219:  40%|███▉      | 21/53 [05:12<07:30, 14.09s/it]loss: 3.3145, accuracy: 0.4219:  42%|████▏     | 22/53 [05:26<07:16, 14.09s/it]loss: 3.3129, accuracy: 0.3906:  42%|████▏     | 22/53 [05:26<07:16, 14.09s/it]loss: 3.3129, accuracy: 0.3906:  43%|████▎     | 23/53 [05:40<07:01, 14.05s/it]loss: 3.4128, accuracy: 0.3750:  43%|████▎     | 23/53 [05:40<07:01, 14.05s/it]loss: 3.4128, accuracy: 0.3750:  45%|████▌     | 24/53 [05:55<06:52, 14.21s/it]loss: 3.2405, accuracy: 0.4375:  45%|████▌     | 24/53 [05:55<06:52, 14.21s/it]loss: 3.2405, accuracy: 0.4375:  47%|████▋     | 25/53 [06:09<06:36, 14.17s/it]loss: 3.2977, accuracy: 0.3750:  47%|████▋     | 25/53 [06:09<06:36, 14.17s/it]loss: 3.2977, accuracy: 0.3750:  49%|████▉     | 26/53 [06:23<06:24, 14.22s/it]loss: 3.0023, accuracy: 0.4688:  49%|████▉     | 26/53 [06:23<06:24, 14.22s/it]loss: 3.0023, accuracy: 0.4688:  51%|█████     | 27/53 [06:37<06:10, 14.25s/it]loss: 3.2037, accuracy: 0.3281:  51%|█████     | 27/53 [06:37<06:10, 14.25s/it]loss: 3.2037, accuracy: 0.3281:  53%|█████▎    | 28/53 [06:52<05:56, 14.26s/it]loss: 3.1954, accuracy: 0.4531:  53%|█████▎    | 28/53 [06:52<05:56, 14.26s/it]loss: 3.1954, accuracy: 0.4531:  55%|█████▍    | 29/53 [07:06<05:42, 14.28s/it]loss: 3.3142, accuracy: 0.3750:  55%|█████▍    | 29/53 [07:06<05:42, 14.28s/it]loss: 3.3142, accuracy: 0.3750:  57%|█████▋    | 30/53 [07:20<05:27, 14.25s/it]loss: 2.9964, accuracy: 0.4844:  57%|█████▋    | 30/53 [07:20<05:27, 14.25s/it]loss: 2.9964, accuracy: 0.4844:  58%|█████▊    | 31/53 [07:34<05:12, 14.22s/it]loss: 3.1255, accuracy: 0.4219:  58%|█████▊    | 31/53 [07:34<05:12, 14.22s/it]loss: 3.1255, accuracy: 0.4219:  60%|██████    | 32/53 [07:48<04:57, 14.15s/it]loss: 3.4768, accuracy: 0.2812:  60%|██████    | 32/53 [07:48<04:57, 14.15s/it]loss: 3.4768, accuracy: 0.2812:  62%|██████▏   | 33/53 [08:02<04:42, 14.12s/it]loss: 2.9860, accuracy: 0.4688:  62%|██████▏   | 33/53 [08:02<04:42, 14.12s/it]loss: 2.9860, accuracy: 0.4688:  64%|██████▍   | 34/53 [08:16<04:28, 14.11s/it]loss: 3.3704, accuracy: 0.2812:  64%|██████▍   | 34/53 [08:16<04:28, 14.11s/it]loss: 3.3704, accuracy: 0.2812:  66%|██████▌   | 35/53 [08:30<04:13, 14.06s/it]loss: 3.1321, accuracy: 0.3750:  66%|██████▌   | 35/53 [08:30<04:13, 14.06s/it]loss: 3.1321, accuracy: 0.3750:  68%|██████▊   | 36/53 [08:44<03:57, 13.96s/it]loss: 3.2639, accuracy: 0.3750:  68%|██████▊   | 36/53 [08:44<03:57, 13.96s/it]loss: 3.2639, accuracy: 0.3750:  70%|██████▉   | 37/53 [08:58<03:42, 13.93s/it]loss: 3.0880, accuracy: 0.4219:  70%|██████▉   | 37/53 [08:58<03:42, 13.93s/it]loss: 3.0880, accuracy: 0.4219:  72%|███████▏  | 38/53 [09:12<03:29, 14.00s/it]loss: 3.0673, accuracy: 0.3906:  72%|███████▏  | 38/53 [09:12<03:29, 14.00s/it]loss: 3.0673, accuracy: 0.3906:  74%|███████▎  | 39/53 [09:26<03:17, 14.10s/it]loss: 3.1496, accuracy: 0.5156:  74%|███████▎  | 39/53 [09:26<03:17, 14.10s/it]loss: 3.1496, accuracy: 0.5156:  75%|███████▌  | 40/53 [09:41<03:04, 14.17s/it]loss: 3.2720, accuracy: 0.3281:  75%|███████▌  | 40/53 [09:41<03:04, 14.17s/it]loss: 3.2720, accuracy: 0.3281:  77%|███████▋  | 41/53 [09:55<02:49, 14.15s/it]loss: 3.3822, accuracy: 0.2969:  77%|███████▋  | 41/53 [09:55<02:49, 14.15s/it]loss: 3.3822, accuracy: 0.2969:  79%|███████▉  | 42/53 [10:09<02:35, 14.16s/it]loss: 3.3602, accuracy: 0.3281:  79%|███████▉  | 42/53 [10:09<02:35, 14.16s/it]loss: 3.3602, accuracy: 0.3281:  81%|████████  | 43/53 [10:24<02:22, 14.27s/it]loss: 3.5964, accuracy: 0.2188:  81%|████████  | 43/53 [10:24<02:22, 14.27s/it]loss: 3.5964, accuracy: 0.2188:  83%|████████▎ | 44/53 [10:38<02:08, 14.31s/it]loss: 3.4232, accuracy: 0.2656:  83%|████████▎ | 44/53 [10:38<02:08, 14.31s/it]loss: 3.4232, accuracy: 0.2656:  85%|████████▍ | 45/53 [10:52<01:54, 14.25s/it]loss: 3.3777, accuracy: 0.3125:  85%|████████▍ | 45/53 [10:52<01:54, 14.25s/it]loss: 3.3777, accuracy: 0.3125:  87%|████████▋ | 46/53 [11:06<01:39, 14.26s/it]loss: 3.1904, accuracy: 0.3125:  87%|████████▋ | 46/53 [11:06<01:39, 14.26s/it]loss: 3.1904, accuracy: 0.3125:  89%|████████▊ | 47/53 [11:20<01:25, 14.18s/it]loss: 2.9058, accuracy: 0.5000:  89%|████████▊ | 47/53 [11:20<01:25, 14.18s/it]loss: 2.9058, accuracy: 0.5000:  91%|█████████ | 48/53 [11:35<01:10, 14.19s/it]loss: 3.3689, accuracy: 0.3594:  91%|█████████ | 48/53 [11:35<01:10, 14.19s/it]loss: 3.3689, accuracy: 0.3594:  92%|█████████▏| 49/53 [11:49<00:56, 14.15s/it]loss: 3.2342, accuracy: 0.3750:  92%|█████████▏| 49/53 [11:49<00:56, 14.15s/it]loss: 3.2342, accuracy: 0.3750:  94%|█████████▍| 50/53 [12:02<00:42, 14.05s/it]loss: 3.1166, accuracy: 0.4375:  94%|█████████▍| 50/53 [12:02<00:42, 14.05s/it]loss: 3.1166, accuracy: 0.4375:  96%|█████████▌| 51/53 [12:16<00:27, 14.00s/it]loss: 2.9597, accuracy: 0.4375:  96%|█████████▌| 51/53 [12:16<00:27, 14.00s/it]loss: 2.9597, accuracy: 0.4375:  98%|█████████▊| 52/53 [12:30<00:13, 13.98s/it]loss: 3.0368, accuracy: 0.3906:  98%|█████████▊| 52/53 [12:30<00:13, 13.98s/it]loss: 3.0368, accuracy: 0.3906: 100%|██████████| 53/53 [12:34<00:00, 11.01s/it]loss: 2.5978, accuracy: 0.5000: 100%|██████████| 53/53 [12:34<00:00, 11.01s/it]loss: 2.5978, accuracy: 0.5000: 100%|██████████| 53/53 [12:34<00:00, 14.24s/it]
  0%|          | 0/53 [00:00<?, ?it/s]  2%|▏         | 1/53 [00:13<11:37, 13.41s/it]loss: 3.9449, accuracy: 0.2344:   2%|▏         | 1/53 [00:13<11:37, 13.41s/it]loss: 3.9449, accuracy: 0.2344:   4%|▍         | 2/53 [00:26<11:28, 13.49s/it]loss: 3.4567, accuracy: 0.3125:   4%|▍         | 2/53 [00:26<11:28, 13.49s/it]loss: 3.4567, accuracy: 0.3125:   6%|▌         | 3/53 [00:40<11:22, 13.65s/it]loss: 3.7717, accuracy: 0.1719:   6%|▌         | 3/53 [00:40<11:22, 13.65s/it]loss: 3.7717, accuracy: 0.1719:   8%|▊         | 4/53 [00:54<11:08, 13.65s/it]loss: 3.9630, accuracy: 0.1875:   8%|▊         | 4/53 [00:54<11:08, 13.65s/it]loss: 3.9630, accuracy: 0.1875:   9%|▉         | 5/53 [01:08<10:56, 13.68s/it]loss: 4.1203, accuracy: 0.1875:   9%|▉         | 5/53 [01:08<10:56, 13.68s/it]loss: 4.1203, accuracy: 0.1875:  11%|█▏        | 6/53 [01:21<10:38, 13.59s/it]loss: 4.1245, accuracy: 0.1875:  11%|█▏        | 6/53 [01:21<10:38, 13.59s/it]loss: 4.1245, accuracy: 0.1875:  13%|█▎        | 7/53 [01:36<10:38, 13.88s/it]loss: 3.7695, accuracy: 0.2812:  13%|█▎        | 7/53 [01:36<10:38, 13.88s/it]loss: 3.7695, accuracy: 0.2812:  15%|█▌        | 8/53 [01:49<10:24, 13.89s/it]loss: 3.7789, accuracy: 0.2344:  15%|█▌        | 8/53 [01:49<10:24, 13.89s/it]loss: 3.7789, accuracy: 0.2344:  17%|█▋        | 9/53 [02:03<10:01, 13.67s/it]loss: 3.9663, accuracy: 0.1875:  17%|█▋        | 9/53 [02:03<10:01, 13.67s/it]loss: 3.9663, accuracy: 0.1875:  19%|█▉        | 10/53 [02:16<09:48, 13.69s/it]loss: 4.1693, accuracy: 0.1406:  19%|█▉        | 10/53 [02:16<09:48, 13.69s/it]loss: 4.1693, accuracy: 0.1406:  21%|██        | 11/53 [02:30<09:30, 13.58s/it]loss: 3.8341, accuracy: 0.2188:  21%|██        | 11/53 [02:30<09:30, 13.58s/it]loss: 3.8341, accuracy: 0.2188:  23%|██▎       | 12/53 [02:43<09:14, 13.53s/it]loss: 4.0985, accuracy: 0.2344:  23%|██▎       | 12/53 [02:43<09:14, 13.53s/it]loss: 4.0985, accuracy: 0.2344:  25%|██▍       | 13/53 [02:57<09:02, 13.57s/it]loss: 3.6934, accuracy: 0.2656:  25%|██▍       | 13/53 [02:57<09:02, 13.57s/it]loss: 3.6934, accuracy: 0.2656:  26%|██▋       | 14/53 [03:10<08:46, 13.51s/it]loss: 3.9455, accuracy: 0.2344:  26%|██▋       | 14/53 [03:10<08:46, 13.51s/it]loss: 3.9455, accuracy: 0.2344:  28%|██▊       | 15/53 [03:24<08:32, 13.49s/it]loss: 4.1429, accuracy: 0.2500:  28%|██▊       | 15/53 [03:24<08:32, 13.49s/it]loss: 4.1429, accuracy: 0.2500:  30%|███       | 16/53 [03:37<08:20, 13.52s/it]loss: 3.7899, accuracy: 0.2344:  30%|███       | 16/53 [03:37<08:20, 13.52s/it]loss: 3.7899, accuracy: 0.2344:  32%|███▏      | 17/53 [03:51<08:09, 13.60s/it]loss: 4.0009, accuracy: 0.1719:  32%|███▏      | 17/53 [03:51<08:09, 13.60s/it]loss: 4.0009, accuracy: 0.1719:  34%|███▍      | 18/53 [04:04<07:54, 13.56s/it]loss: 3.9823, accuracy: 0.2344:  34%|███▍      | 18/53 [04:04<07:54, 13.56s/it]loss: 3.9823, accuracy: 0.2344:  36%|███▌      | 19/53 [04:18<07:41, 13.58s/it]loss: 4.1666, accuracy: 0.1094:  36%|███▌      | 19/53 [04:18<07:41, 13.58s/it]loss: 4.1666, accuracy: 0.1094:  38%|███▊      | 20/53 [04:32<07:28, 13.59s/it]loss: 4.2280, accuracy: 0.1562:  38%|███▊      | 20/53 [04:32<07:28, 13.59s/it]loss: 4.2280, accuracy: 0.1562:  40%|███▉      | 21/53 [04:45<07:12, 13.52s/it]loss: 3.6656, accuracy: 0.2812:  40%|███▉      | 21/53 [04:45<07:12, 13.52s/it]loss: 3.6656, accuracy: 0.2812:  42%|████▏     | 22/53 [04:58<06:57, 13.46s/it]loss: 3.6428, accuracy: 0.2656:  42%|████▏     | 22/53 [04:58<06:57, 13.46s/it]loss: 3.6428, accuracy: 0.2656:  43%|████▎     | 23/53 [05:12<06:43, 13.45s/it]loss: 4.1564, accuracy: 0.1719:  43%|████▎     | 23/53 [05:12<06:43, 13.45s/it]loss: 4.1564, accuracy: 0.1719:  45%|████▌     | 24/53 [05:25<06:30, 13.45s/it]loss: 3.7985, accuracy: 0.3438:  45%|████▌     | 24/53 [05:25<06:30, 13.45s/it]loss: 3.7985, accuracy: 0.3438:  47%|████▋     | 25/53 [05:39<06:15, 13.43s/it]loss: 3.8396, accuracy: 0.2969:  47%|████▋     | 25/53 [05:39<06:15, 13.43s/it]loss: 3.8396, accuracy: 0.2969:  49%|████▉     | 26/53 [05:52<06:02, 13.43s/it]loss: 4.1408, accuracy: 0.2188:  49%|████▉     | 26/53 [05:52<06:02, 13.43s/it]loss: 4.1408, accuracy: 0.2188:  51%|█████     | 27/53 [06:05<05:48, 13.42s/it]loss: 4.2200, accuracy: 0.1719:  51%|█████     | 27/53 [06:05<05:48, 13.42s/it]loss: 4.2200, accuracy: 0.1719:  53%|█████▎    | 28/53 [06:19<05:36, 13.46s/it]loss: 4.0287, accuracy: 0.2031:  53%|█████▎    | 28/53 [06:19<05:36, 13.46s/it]loss: 4.0287, accuracy: 0.2031:  55%|█████▍    | 29/53 [06:32<05:22, 13.44s/it]loss: 4.1903, accuracy: 0.2344:  55%|█████▍    | 29/53 [06:32<05:22, 13.44s/it]loss: 4.1903, accuracy: 0.2344:  57%|█████▋    | 30/53 [06:47<05:15, 13.74s/it]loss: 4.0172, accuracy: 0.2188:  57%|█████▋    | 30/53 [06:47<05:15, 13.74s/it]loss: 4.0172, accuracy: 0.2188:  58%|█████▊    | 31/53 [07:00<05:00, 13.64s/it]loss: 3.8532, accuracy: 0.2344:  58%|█████▊    | 31/53 [07:00<05:00, 13.64s/it]loss: 3.8532, accuracy: 0.2344:  60%|██████    | 32/53 [07:14<04:44, 13.56s/it]loss: 4.2251, accuracy: 0.1562:  60%|██████    | 32/53 [07:14<04:44, 13.56s/it]loss: 4.2251, accuracy: 0.1562:  62%|██████▏   | 33/53 [07:30<04:50, 14.52s/it]loss: 3.9683, accuracy: 0.1875:  62%|██████▏   | 33/53 [07:30<04:50, 14.52s/it]loss: 3.9683, accuracy: 0.1875:  64%|██████▍   | 34/53 [07:44<04:31, 14.28s/it]loss: 4.0254, accuracy: 0.2188:  64%|██████▍   | 34/53 [07:44<04:31, 14.28s/it]loss: 4.0254, accuracy: 0.2188:  66%|██████▌   | 35/53 [07:58<04:13, 14.11s/it]loss: 4.0462, accuracy: 0.2188:  66%|██████▌   | 35/53 [07:58<04:13, 14.11s/it]loss: 4.0462, accuracy: 0.2188:  68%|██████▊   | 36/53 [08:11<03:56, 13.90s/it]loss: 4.1394, accuracy: 0.1875:  68%|██████▊   | 36/53 [08:11<03:56, 13.90s/it]loss: 4.1394, accuracy: 0.1875:  70%|██████▉   | 37/53 [08:25<03:39, 13.73s/it]loss: 3.9871, accuracy: 0.2031:  70%|██████▉   | 37/53 [08:25<03:39, 13.73s/it]loss: 3.9871, accuracy: 0.2031:  72%|███████▏  | 38/53 [08:38<03:24, 13.62s/it]loss: 3.9525, accuracy: 0.1562:  72%|███████▏  | 38/53 [08:38<03:24, 13.62s/it]loss: 3.9525, accuracy: 0.1562:  74%|███████▎  | 39/53 [08:51<03:09, 13.56s/it]loss: 3.4085, accuracy: 0.3906:  74%|███████▎  | 39/53 [08:51<03:09, 13.56s/it]loss: 3.4085, accuracy: 0.3906:  75%|███████▌  | 40/53 [09:05<02:55, 13.52s/it]loss: 3.9890, accuracy: 0.2344:  75%|███████▌  | 40/53 [09:05<02:55, 13.52s/it]loss: 3.9890, accuracy: 0.2344:  77%|███████▋  | 41/53 [09:18<02:42, 13.50s/it]loss: 3.6914, accuracy: 0.2500:  77%|███████▋  | 41/53 [09:18<02:42, 13.50s/it]loss: 3.6914, accuracy: 0.2500:  79%|███████▉  | 42/53 [09:33<02:33, 13.94s/it]loss: 4.0350, accuracy: 0.2500:  79%|███████▉  | 42/53 [09:33<02:33, 13.94s/it]loss: 4.0350, accuracy: 0.2500:  81%|████████  | 43/53 [09:47<02:18, 13.86s/it]loss: 4.0175, accuracy: 0.2188:  81%|████████  | 43/53 [09:47<02:18, 13.86s/it]loss: 4.0175, accuracy: 0.2188:  83%|████████▎ | 44/53 [10:00<02:03, 13.72s/it]loss: 3.8237, accuracy: 0.2500:  83%|████████▎ | 44/53 [10:00<02:03, 13.72s/it]loss: 3.8237, accuracy: 0.2500:  85%|████████▍ | 45/53 [10:14<01:50, 13.77s/it]loss: 3.9087, accuracy: 0.2500:  85%|████████▍ | 45/53 [10:14<01:50, 13.77s/it]loss: 3.9087, accuracy: 0.2500:  87%|████████▋ | 46/53 [10:28<01:35, 13.68s/it]loss: 3.6745, accuracy: 0.2969:  87%|████████▋ | 46/53 [10:28<01:35, 13.68s/it]loss: 3.6745, accuracy: 0.2969:  89%|████████▊ | 47/53 [10:42<01:22, 13.74s/it]loss: 4.0851, accuracy: 0.1719:  89%|████████▊ | 47/53 [10:42<01:22, 13.74s/it]loss: 4.0851, accuracy: 0.1719:  91%|█████████ | 48/53 [10:55<01:08, 13.70s/it]loss: 3.9059, accuracy: 0.1719:  91%|█████████ | 48/53 [10:55<01:08, 13.70s/it]loss: 3.9059, accuracy: 0.1719:  92%|█████████▏| 49/53 [11:08<00:54, 13.60s/it]loss: 4.0958, accuracy: 0.1719:  92%|█████████▏| 49/53 [11:09<00:54, 13.60s/it]loss: 4.0958, accuracy: 0.1719:  94%|█████████▍| 50/53 [11:22<00:40, 13.56s/it]loss: 3.9431, accuracy: 0.2188:  94%|█████████▍| 50/53 [11:22<00:40, 13.56s/it]loss: 3.9431, accuracy: 0.2188:  96%|█████████▌| 51/53 [11:35<00:27, 13.52s/it]loss: 3.8895, accuracy: 0.1719:  96%|█████████▌| 51/53 [11:35<00:27, 13.52s/it]loss: 3.8895, accuracy: 0.1719:  98%|█████████▊| 52/53 [11:49<00:13, 13.51s/it]loss: 3.7512, accuracy: 0.2656:  98%|█████████▊| 52/53 [11:49<00:13, 13.51s/it]loss: 3.7512, accuracy: 0.2656: 100%|██████████| 53/53 [11:52<00:00, 10.30s/it]loss: 5.2718, accuracy: 0.0000: 100%|██████████| 53/53 [11:52<00:00, 10.30s/it]loss: 5.2718, accuracy: 0.0000: 100%|██████████| 53/53 [11:52<00:00, 13.44s/it]
Epoch 23: train_acc_0.3939_train_loss_3.2075_val_acc_0.2173_val_loss_3.9686 epoch time 1467.0008 seconds
  0%|          | 0/53 [00:00<?, ?it/s]  2%|▏         | 1/53 [00:11<10:07, 11.69s/it]loss: 2.9562, accuracy: 0.4688:   2%|▏         | 1/53 [00:11<10:07, 11.69s/it]loss: 2.9562, accuracy: 0.4688:   4%|▍         | 2/53 [00:23<09:50, 11.58s/it]loss: 2.7894, accuracy: 0.5469:   4%|▍         | 2/53 [00:23<09:50, 11.58s/it]loss: 2.7894, accuracy: 0.5469:   6%|▌         | 3/53 [00:34<09:40, 11.60s/it]loss: 3.0259, accuracy: 0.4531:   6%|▌         | 3/53 [00:34<09:40, 11.60s/it]loss: 3.0259, accuracy: 0.4531:   8%|▊         | 4/53 [00:46<09:26, 11.56s/it]loss: 3.0701, accuracy: 0.5469:   8%|▊         | 4/53 [00:46<09:26, 11.56s/it]loss: 3.0701, accuracy: 0.5469:   9%|▉         | 5/53 [00:57<09:14, 11.55s/it]loss: 2.8854, accuracy: 0.5312:   9%|▉         | 5/53 [00:57<09:14, 11.55s/it]loss: 2.8854, accuracy: 0.5312:  11%|█▏        | 6/53 [01:09<09:05, 11.61s/it]loss: 3.1720, accuracy: 0.4375:  11%|█▏        | 6/53 [01:09<09:05, 11.61s/it]loss: 3.1720, accuracy: 0.4375:  13%|█▎        | 7/53 [01:21<08:52, 11.58s/it]loss: 2.8754, accuracy: 0.4844:  13%|█▎        | 7/53 [01:21<08:52, 11.58s/it]loss: 2.8754, accuracy: 0.4844:  15%|█▌        | 8/53 [01:32<08:40, 11.57s/it]loss: 2.7975, accuracy: 0.5625:  15%|█▌        | 8/53 [01:32<08:40, 11.57s/it]loss: 2.7975, accuracy: 0.5625:  17%|█▋        | 9/53 [01:44<08:29, 11.58s/it]loss: 3.1418, accuracy: 0.4062:  17%|█▋        | 9/53 [01:44<08:29, 11.58s/it]loss: 3.1418, accuracy: 0.4062:  19%|█▉        | 10/53 [01:55<08:18, 11.58s/it]loss: 3.0672, accuracy: 0.4688:  19%|█▉        | 10/53 [01:55<08:18, 11.58s/it]loss: 3.0672, accuracy: 0.4688:  21%|██        | 11/53 [02:07<08:06, 11.58s/it]loss: 3.1369, accuracy: 0.4219:  21%|██        | 11/53 [02:07<08:06, 11.58s/it]loss: 3.1369, accuracy: 0.4219:  23%|██▎       | 12/53 [02:18<07:54, 11.57s/it]loss: 2.7498, accuracy: 0.5625:  23%|██▎       | 12/53 [02:18<07:54, 11.57s/it]loss: 2.7498, accuracy: 0.5625:  25%|██▍       | 13/53 [02:30<07:41, 11.54s/it]loss: 3.2515, accuracy: 0.3750:  25%|██▍       | 13/53 [02:30<07:41, 11.54s/it]loss: 3.2515, accuracy: 0.3750:  26%|██▋       | 14/53 [02:41<07:29, 11.52s/it]loss: 3.1219, accuracy: 0.4688:  26%|██▋       | 14/53 [02:41<07:29, 11.52s/it]loss: 3.1219, accuracy: 0.4688:  28%|██▊       | 15/53 [02:53<07:18, 11.53s/it]loss: 3.2251, accuracy: 0.4062:  28%|██▊       | 15/53 [02:53<07:18, 11.53s/it]loss: 3.2251, accuracy: 0.4062:  30%|███       | 16/53 [03:05<07:07, 11.56s/it]loss: 2.9517, accuracy: 0.3906:  30%|███       | 16/53 [03:05<07:07, 11.56s/it]loss: 2.9517, accuracy: 0.3906:  32%|███▏      | 17/53 [03:16<06:57, 11.60s/it]loss: 2.9948, accuracy: 0.4688:  32%|███▏      | 17/53 [03:16<06:57, 11.60s/it]loss: 2.9948, accuracy: 0.4688:  34%|███▍      | 18/53 [03:28<06:46, 11.60s/it]loss: 3.0500, accuracy: 0.4062:  34%|███▍      | 18/53 [03:28<06:46, 11.60s/it]loss: 3.0500, accuracy: 0.4062:  36%|███▌      | 19/53 [03:39<06:34, 11.60s/it]loss: 3.2842, accuracy: 0.3594:  36%|███▌      | 19/53 [03:39<06:34, 11.60s/it]loss: 3.2842, accuracy: 0.3594:  38%|███▊      | 20/53 [03:51<06:23, 11.61s/it]loss: 2.8924, accuracy: 0.4375:  38%|███▊      | 20/53 [03:51<06:23, 11.61s/it]loss: 2.8924, accuracy: 0.4375:  40%|███▉      | 21/53 [04:03<06:10, 11.58s/it]loss: 3.1063, accuracy: 0.4375:  40%|███▉      | 21/53 [04:03<06:10, 11.58s/it]loss: 3.1063, accuracy: 0.4375:  42%|████▏     | 22/53 [04:14<05:58, 11.58s/it]loss: 3.0563, accuracy: 0.4219:  42%|████▏     | 22/53 [04:14<05:58, 11.58s/it]loss: 3.0563, accuracy: 0.4219:  43%|████▎     | 23/53 [04:26<05:47, 11.59s/it]loss: 2.9813, accuracy: 0.4531:  43%|████▎     | 23/53 [04:26<05:47, 11.59s/it]loss: 2.9813, accuracy: 0.4531:  45%|████▌     | 24/53 [04:37<05:35, 11.56s/it]loss: 3.0553, accuracy: 0.4688:  45%|████▌     | 24/53 [04:37<05:35, 11.56s/it]loss: 3.0553, accuracy: 0.4688:  47%|████▋     | 25/53 [04:49<05:23, 11.55s/it]loss: 3.1026, accuracy: 0.3906:  47%|████▋     | 25/53 [04:49<05:23, 11.55s/it]loss: 3.1026, accuracy: 0.3906:  49%|████▉     | 26/53 [05:00<05:11, 11.54s/it]loss: 2.8761, accuracy: 0.5000:  49%|████▉     | 26/53 [05:00<05:11, 11.54s/it]loss: 2.8761, accuracy: 0.5000:  51%|█████     | 27/53 [05:12<05:00, 11.55s/it]loss: 3.0901, accuracy: 0.4375:  51%|█████     | 27/53 [05:12<05:00, 11.55s/it]loss: 3.0901, accuracy: 0.4375:  53%|█████▎    | 28/53 [05:24<04:49, 11.58s/it]loss: 3.2720, accuracy: 0.3906:  53%|█████▎    | 28/53 [05:24<04:49, 11.58s/it]loss: 3.2720, accuracy: 0.3906:  55%|█████▍    | 29/53 [05:35<04:37, 11.56s/it]loss: 3.0656, accuracy: 0.4219:  55%|█████▍    | 29/53 [05:35<04:37, 11.56s/it]loss: 3.0656, accuracy: 0.4219:  57%|█████▋    | 30/53 [05:47<04:25, 11.56s/it]loss: 3.0559, accuracy: 0.4375:  57%|█████▋    | 30/53 [05:47<04:25, 11.56s/it]loss: 3.0559, accuracy: 0.4375:  58%|█████▊    | 31/53 [05:58<04:13, 11.54s/it]loss: 3.0563, accuracy: 0.4531:  58%|█████▊    | 31/53 [05:58<04:13, 11.54s/it]loss: 3.0563, accuracy: 0.4531:  60%|██████    | 32/53 [06:10<04:01, 11.52s/it]loss: 3.0306, accuracy: 0.4844:  60%|██████    | 32/53 [06:10<04:01, 11.52s/it]loss: 3.0306, accuracy: 0.4844:  62%|██████▏   | 33/53 [06:21<03:50, 11.53s/it]loss: 3.0911, accuracy: 0.4219:  62%|██████▏   | 33/53 [06:21<03:50, 11.53s/it]loss: 3.0911, accuracy: 0.4219:  64%|██████▍   | 34/53 [06:33<03:39, 11.53s/it]loss: 3.2294, accuracy: 0.3594:  64%|██████▍   | 34/53 [06:33<03:39, 11.53s/it]loss: 3.2294, accuracy: 0.3594:  66%|██████▌   | 35/53 [06:44<03:27, 11.53s/it]loss: 3.0423, accuracy: 0.4219:  66%|██████▌   | 35/53 [06:44<03:27, 11.53s/it]loss: 3.0423, accuracy: 0.4219:  68%|██████▊   | 36/53 [06:56<03:16, 11.54s/it]loss: 3.0448, accuracy: 0.3906:  68%|██████▊   | 36/53 [06:56<03:16, 11.54s/it]loss: 3.0448, accuracy: 0.3906:  70%|██████▉   | 37/53 [07:07<03:04, 11.56s/it]loss: 3.0805, accuracy: 0.4219:  70%|██████▉   | 37/53 [07:07<03:04, 11.56s/it]loss: 3.0805, accuracy: 0.4219:  72%|███████▏  | 38/53 [07:19<02:53, 11.56s/it]loss: 2.9495, accuracy: 0.4688:  72%|███████▏  | 38/53 [07:19<02:53, 11.56s/it]loss: 2.9495, accuracy: 0.4688:  74%|███████▎  | 39/53 [07:30<02:41, 11.55s/it]loss: 3.0950, accuracy: 0.4531:  74%|███████▎  | 39/53 [07:30<02:41, 11.55s/it]loss: 3.0950, accuracy: 0.4531:  75%|███████▌  | 40/53 [07:42<02:30, 11.55s/it]loss: 2.9112, accuracy: 0.5625:  75%|███████▌  | 40/53 [07:42<02:30, 11.55s/it]loss: 2.9112, accuracy: 0.5625:  77%|███████▋  | 41/53 [07:54<02:18, 11.55s/it]loss: 3.2487, accuracy: 0.2969:  77%|███████▋  | 41/53 [07:54<02:18, 11.55s/it]loss: 3.2487, accuracy: 0.2969:  79%|███████▉  | 42/53 [08:05<02:06, 11.54s/it]loss: 2.9849, accuracy: 0.5469:  79%|███████▉  | 42/53 [08:05<02:06, 11.54s/it]loss: 2.9849, accuracy: 0.5469:  81%|████████  | 43/53 [08:17<01:55, 11.54s/it]loss: 3.1250, accuracy: 0.4531:  81%|████████  | 43/53 [08:17<01:55, 11.54s/it]loss: 3.1250, accuracy: 0.4531:  83%|████████▎ | 44/53 [08:28<01:43, 11.52s/it]loss: 2.7323, accuracy: 0.5156:  83%|████████▎ | 44/53 [08:28<01:43, 11.52s/it]loss: 2.7323, accuracy: 0.5156:  85%|████████▍ | 45/53 [08:40<01:32, 11.54s/it]loss: 2.8448, accuracy: 0.5156:  85%|████████▍ | 45/53 [08:40<01:32, 11.54s/it]loss: 2.8448, accuracy: 0.5156:  87%|████████▋ | 46/53 [08:51<01:20, 11.56s/it]loss: 3.0940, accuracy: 0.3281:  87%|████████▋ | 46/53 [08:51<01:20, 11.56s/it]loss: 3.0940, accuracy: 0.3281:  89%|████████▊ | 47/53 [09:03<01:09, 11.56s/it]loss: 3.0723, accuracy: 0.4688:  89%|████████▊ | 47/53 [09:03<01:09, 11.56s/it]loss: 3.0723, accuracy: 0.4688:  91%|█████████ | 48/53 [09:14<00:57, 11.57s/it]loss: 2.9474, accuracy: 0.4375:  91%|█████████ | 48/53 [09:14<00:57, 11.57s/it]loss: 2.9474, accuracy: 0.4375:  92%|█████████▏| 49/53 [09:26<00:46, 11.60s/it]loss: 2.8003, accuracy: 0.5469:  92%|█████████▏| 49/53 [09:26<00:46, 11.60s/it]loss: 2.8003, accuracy: 0.5469:  94%|█████████▍| 50/53 [09:38<00:34, 11.64s/it]loss: 2.9763, accuracy: 0.4375:  94%|█████████▍| 50/53 [09:38<00:34, 11.64s/it]loss: 2.9763, accuracy: 0.4375:  96%|█████████▌| 51/53 [09:49<00:23, 11.60s/it]loss: 3.0182, accuracy: 0.4688:  96%|█████████▌| 51/53 [09:49<00:23, 11.60s/it]loss: 3.0182, accuracy: 0.4688:  98%|█████████▊| 52/53 [10:01<00:11, 11.55s/it]loss: 2.9632, accuracy: 0.4531:  98%|█████████▊| 52/53 [10:01<00:11, 11.55s/it]loss: 2.9632, accuracy: 0.4531: 100%|██████████| 53/53 [10:02<00:00,  8.58s/it]loss: 3.3773, accuracy: 0.1667: 100%|██████████| 53/53 [10:02<00:00,  8.58s/it]loss: 3.3773, accuracy: 0.1667: 100%|██████████| 53/53 [10:02<00:00, 11.38s/it]
  0%|          | 0/53 [00:00<?, ?it/s]  2%|▏         | 1/53 [00:11<09:33, 11.03s/it]loss: 3.9851, accuracy: 0.2656:   2%|▏         | 1/53 [00:11<09:33, 11.03s/it]loss: 3.9851, accuracy: 0.2656:   4%|▍         | 2/53 [00:21<09:18, 10.95s/it]loss: 4.2259, accuracy: 0.2031:   4%|▍         | 2/53 [00:21<09:18, 10.95s/it]loss: 4.2259, accuracy: 0.2031:   6%|▌         | 3/53 [00:32<09:09, 10.98s/it]loss: 3.9291, accuracy: 0.2031:   6%|▌         | 3/53 [00:32<09:09, 10.98s/it]loss: 3.9291, accuracy: 0.2031:   8%|▊         | 4/53 [00:43<08:58, 10.99s/it]loss: 3.6689, accuracy: 0.2344:   8%|▊         | 4/53 [00:43<08:58, 10.99s/it]loss: 3.6689, accuracy: 0.2344:   9%|▉         | 5/53 [00:54<08:47, 10.98s/it]loss: 4.1380, accuracy: 0.2031:   9%|▉         | 5/53 [00:54<08:47, 10.98s/it]loss: 4.1380, accuracy: 0.2031:  11%|█▏        | 6/53 [01:05<08:37, 11.00s/it]loss: 3.7049, accuracy: 0.2500:  11%|█▏        | 6/53 [01:05<08:37, 11.00s/it]loss: 3.7049, accuracy: 0.2500:  13%|█▎        | 7/53 [01:16<08:25, 10.99s/it]loss: 3.8853, accuracy: 0.2031:  13%|█▎        | 7/53 [01:16<08:25, 10.99s/it]loss: 3.8853, accuracy: 0.2031:  15%|█▌        | 8/53 [01:28<08:15, 11.02s/it]loss: 3.7497, accuracy: 0.2656:  15%|█▌        | 8/53 [01:28<08:15, 11.02s/it]loss: 3.7497, accuracy: 0.2656:  17%|█▋        | 9/53 [01:38<08:04, 11.00s/it]loss: 3.8602, accuracy: 0.2812:  17%|█▋        | 9/53 [01:38<08:04, 11.00s/it]loss: 3.8602, accuracy: 0.2812:  19%|█▉        | 10/53 [01:49<07:51, 10.97s/it]loss: 3.5762, accuracy: 0.2500:  19%|█▉        | 10/53 [01:49<07:51, 10.97s/it]loss: 3.5762, accuracy: 0.2500:  21%|██        | 11/53 [02:00<07:41, 11.00s/it]loss: 3.6340, accuracy: 0.2031:  21%|██        | 11/53 [02:00<07:41, 11.00s/it]loss: 3.6340, accuracy: 0.2031:  23%|██▎       | 12/53 [02:11<07:30, 11.00s/it]loss: 3.8235, accuracy: 0.2188:  23%|██▎       | 12/53 [02:11<07:30, 11.00s/it]loss: 3.8235, accuracy: 0.2188:  25%|██▍       | 13/53 [02:22<07:19, 10.99s/it]loss: 3.6634, accuracy: 0.2656:  25%|██▍       | 13/53 [02:22<07:19, 10.99s/it]loss: 3.6634, accuracy: 0.2656:  26%|██▋       | 14/53 [02:33<07:07, 10.97s/it]loss: 4.0508, accuracy: 0.2656:  26%|██▋       | 14/53 [02:33<07:07, 10.97s/it]loss: 4.0508, accuracy: 0.2656:  28%|██▊       | 15/53 [02:44<06:56, 10.97s/it]loss: 3.5562, accuracy: 0.3281:  28%|██▊       | 15/53 [02:44<06:56, 10.97s/it]loss: 3.5562, accuracy: 0.3281:  30%|███       | 16/53 [02:55<06:45, 10.97s/it]loss: 3.7762, accuracy: 0.2344:  30%|███       | 16/53 [02:55<06:45, 10.97s/it]loss: 3.7762, accuracy: 0.2344:  32%|███▏      | 17/53 [03:06<06:35, 10.98s/it]loss: 4.2662, accuracy: 0.2031:  32%|███▏      | 17/53 [03:06<06:35, 10.98s/it]loss: 4.2662, accuracy: 0.2031:  34%|███▍      | 18/53 [03:17<06:23, 10.97s/it]loss: 3.8808, accuracy: 0.2031:  34%|███▍      | 18/53 [03:17<06:23, 10.97s/it]loss: 3.8808, accuracy: 0.2031:  36%|███▌      | 19/53 [03:28<06:12, 10.95s/it]loss: 4.3003, accuracy: 0.1875:  36%|███▌      | 19/53 [03:28<06:12, 10.95s/it]loss: 4.3003, accuracy: 0.1875:  38%|███▊      | 20/53 [03:39<06:03, 11.01s/it]loss: 3.5957, accuracy: 0.2500:  38%|███▊      | 20/53 [03:39<06:03, 11.01s/it]loss: 3.5957, accuracy: 0.2500:  40%|███▉      | 21/53 [03:50<05:51, 10.99s/it]loss: 3.9629, accuracy: 0.1719:  40%|███▉      | 21/53 [03:50<05:51, 10.99s/it]loss: 3.9629, accuracy: 0.1719:  42%|████▏     | 22/53 [04:01<05:40, 10.99s/it]loss: 3.9964, accuracy: 0.1875:  42%|████▏     | 22/53 [04:01<05:40, 10.99s/it]loss: 3.9964, accuracy: 0.1875:  43%|████▎     | 23/53 [04:12<05:29, 10.98s/it]loss: 3.7098, accuracy: 0.2656:  43%|████▎     | 23/53 [04:12<05:29, 10.98s/it]loss: 3.7098, accuracy: 0.2656:  45%|████▌     | 24/53 [04:23<05:18, 10.97s/it]loss: 3.8737, accuracy: 0.2656:  45%|████▌     | 24/53 [04:23<05:18, 10.97s/it]loss: 3.8737, accuracy: 0.2656:  47%|████▋     | 25/53 [04:34<05:06, 10.95s/it]loss: 3.6036, accuracy: 0.2812:  47%|████▋     | 25/53 [04:34<05:06, 10.95s/it]loss: 3.6036, accuracy: 0.2812:  49%|████▉     | 26/53 [04:45<04:55, 10.94s/it]loss: 3.9508, accuracy: 0.2188:  49%|████▉     | 26/53 [04:45<04:55, 10.94s/it]loss: 3.9508, accuracy: 0.2188:  51%|█████     | 27/53 [04:56<04:45, 10.97s/it]loss: 4.1461, accuracy: 0.2188:  51%|█████     | 27/53 [04:56<04:45, 10.97s/it]loss: 4.1461, accuracy: 0.2188:  53%|█████▎    | 28/53 [05:07<04:33, 10.95s/it]loss: 4.0922, accuracy: 0.2188:  53%|█████▎    | 28/53 [05:07<04:33, 10.95s/it]loss: 4.0922, accuracy: 0.2188:  55%|█████▍    | 29/53 [05:18<04:23, 10.97s/it]loss: 3.9701, accuracy: 0.1406:  55%|█████▍    | 29/53 [05:18<04:23, 10.97s/it]loss: 3.9701, accuracy: 0.1406:  57%|█████▋    | 30/53 [05:29<04:12, 10.99s/it]loss: 4.1115, accuracy: 0.1875:  57%|█████▋    | 30/53 [05:29<04:12, 10.99s/it]loss: 4.1115, accuracy: 0.1875:  58%|█████▊    | 31/53 [05:40<04:01, 10.99s/it]loss: 3.8695, accuracy: 0.2031:  58%|█████▊    | 31/53 [05:40<04:01, 10.99s/it]loss: 3.8695, accuracy: 0.2031:  60%|██████    | 32/53 [05:51<03:50, 11.00s/it]loss: 4.1201, accuracy: 0.1562:  60%|██████    | 32/53 [05:51<03:50, 11.00s/it]loss: 4.1201, accuracy: 0.1562:  62%|██████▏   | 33/53 [06:02<03:39, 10.99s/it]loss: 4.2061, accuracy: 0.1719:  62%|██████▏   | 33/53 [06:02<03:39, 10.99s/it]loss: 4.2061, accuracy: 0.1719:  64%|██████▍   | 34/53 [06:13<03:28, 10.99s/it]loss: 3.7422, accuracy: 0.2500:  64%|██████▍   | 34/53 [06:13<03:28, 10.99s/it]loss: 3.7422, accuracy: 0.2500:  66%|██████▌   | 35/53 [06:24<03:17, 10.99s/it]loss: 3.7682, accuracy: 0.2812:  66%|██████▌   | 35/53 [06:24<03:17, 10.99s/it]loss: 3.7682, accuracy: 0.2812:  68%|██████▊   | 36/53 [06:35<03:07, 11.00s/it]loss: 3.8611, accuracy: 0.2656:  68%|██████▊   | 36/53 [06:35<03:07, 11.00s/it]loss: 3.8611, accuracy: 0.2656:  70%|██████▉   | 37/53 [06:46<02:56, 11.00s/it]loss: 4.3890, accuracy: 0.1250:  70%|██████▉   | 37/53 [06:46<02:56, 11.00s/it]loss: 4.3890, accuracy: 0.1250:  72%|███████▏  | 38/53 [06:57<02:44, 10.99s/it]loss: 4.0507, accuracy: 0.1250:  72%|███████▏  | 38/53 [06:57<02:44, 10.99s/it]loss: 4.0507, accuracy: 0.1250:  74%|███████▎  | 39/53 [07:08<02:33, 10.99s/it]loss: 4.0644, accuracy: 0.2031:  74%|███████▎  | 39/53 [07:08<02:33, 10.99s/it]loss: 4.0644, accuracy: 0.2031:  75%|███████▌  | 40/53 [07:19<02:22, 10.97s/it]loss: 3.8503, accuracy: 0.2500:  75%|███████▌  | 40/53 [07:19<02:22, 10.97s/it]loss: 3.8503, accuracy: 0.2500:  77%|███████▋  | 41/53 [07:30<02:11, 10.98s/it]loss: 3.9006, accuracy: 0.2500:  77%|███████▋  | 41/53 [07:30<02:11, 10.98s/it]loss: 3.9006, accuracy: 0.2500:  79%|███████▉  | 42/53 [07:41<02:00, 10.96s/it]loss: 4.0232, accuracy: 0.2656:  79%|███████▉  | 42/53 [07:41<02:00, 10.96s/it]loss: 4.0232, accuracy: 0.2656:  81%|████████  | 43/53 [07:52<01:49, 10.93s/it]loss: 4.1129, accuracy: 0.2500:  81%|████████  | 43/53 [07:52<01:49, 10.93s/it]loss: 4.1129, accuracy: 0.2500:  83%|████████▎ | 44/53 [08:03<01:38, 10.97s/it]loss: 4.0188, accuracy: 0.1719:  83%|████████▎ | 44/53 [08:03<01:38, 10.97s/it]loss: 4.0188, accuracy: 0.1719:  85%|████████▍ | 45/53 [08:14<01:27, 10.96s/it]loss: 4.1300, accuracy: 0.1562:  85%|████████▍ | 45/53 [08:14<01:27, 10.96s/it]loss: 4.1300, accuracy: 0.1562:  87%|████████▋ | 46/53 [08:25<01:16, 10.95s/it]loss: 4.3416, accuracy: 0.1562:  87%|████████▋ | 46/53 [08:25<01:16, 10.95s/it]loss: 4.3416, accuracy: 0.1562:  89%|████████▊ | 47/53 [08:35<01:05, 10.95s/it]loss: 4.0392, accuracy: 0.2188:  89%|████████▊ | 47/53 [08:35<01:05, 10.95s/it]loss: 4.0392, accuracy: 0.2188:  91%|█████████ | 48/53 [08:46<00:54, 10.94s/it]loss: 4.1115, accuracy: 0.1406:  91%|█████████ | 48/53 [08:46<00:54, 10.94s/it]loss: 4.1115, accuracy: 0.1406:  92%|█████████▏| 49/53 [08:57<00:43, 10.92s/it]loss: 3.6818, accuracy: 0.2969:  92%|█████████▏| 49/53 [08:57<00:43, 10.92s/it]loss: 3.6818, accuracy: 0.2969:  94%|█████████▍| 50/53 [09:08<00:32, 10.94s/it]loss: 3.8492, accuracy: 0.2656:  94%|█████████▍| 50/53 [09:08<00:32, 10.94s/it]loss: 3.8492, accuracy: 0.2656:  96%|█████████▌| 51/53 [09:19<00:21, 10.94s/it]loss: 4.1910, accuracy: 0.2031:  96%|█████████▌| 51/53 [09:19<00:21, 10.94s/it]loss: 4.1910, accuracy: 0.2031:  98%|█████████▊| 52/53 [09:30<00:10, 10.94s/it]loss: 3.7129, accuracy: 0.2656:  98%|█████████▊| 52/53 [09:30<00:10, 10.94s/it]loss: 3.7129, accuracy: 0.2656: 100%|██████████| 53/53 [09:31<00:00,  7.99s/it]loss: 3.1180, accuracy: 0.2000: 100%|██████████| 53/53 [09:31<00:00,  7.99s/it]loss: 3.1180, accuracy: 0.2000: 100%|██████████| 53/53 [09:31<00:00, 10.79s/it]
Epoch 24: train_acc_0.4460_train_loss_3.0343_val_acc_0.2216_val_loss_3.9215 epoch time 1174.7087 seconds
  0%|          | 0/53 [00:00<?, ?it/s]  2%|▏         | 1/53 [00:14<12:46, 14.74s/it]loss: 3.0663, accuracy: 0.4219:   2%|▏         | 1/53 [00:14<12:46, 14.74s/it]loss: 3.0663, accuracy: 0.4219:   4%|▍         | 2/53 [00:26<10:55, 12.85s/it]loss: 3.0343, accuracy: 0.4219:   4%|▍         | 2/53 [00:26<10:55, 12.85s/it]loss: 3.0343, accuracy: 0.4219:   6%|▌         | 3/53 [00:37<10:13, 12.26s/it]loss: 3.0474, accuracy: 0.4844:   6%|▌         | 3/53 [00:37<10:13, 12.26s/it]loss: 3.0474, accuracy: 0.4844:   8%|▊         | 4/53 [00:49<09:50, 12.05s/it]loss: 2.8770, accuracy: 0.5000:   8%|▊         | 4/53 [00:49<09:50, 12.05s/it]loss: 2.8770, accuracy: 0.5000:   9%|▉         | 5/53 [01:01<09:29, 11.87s/it]loss: 3.1934, accuracy: 0.3750:   9%|▉         | 5/53 [01:01<09:29, 11.87s/it]loss: 3.1934, accuracy: 0.3750:  11%|█▏        | 6/53 [01:12<09:11, 11.74s/it]loss: 3.1233, accuracy: 0.4375:  11%|█▏        | 6/53 [01:12<09:11, 11.74s/it]slurmstepd-landonia20: error: *** JOB 1792366 ON landonia20 CANCELLED AT 2024-03-21T02:12:51 ***
