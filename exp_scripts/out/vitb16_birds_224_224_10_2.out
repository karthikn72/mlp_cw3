Namespace(batch_size=64, continue_from_epoch=-2, seed=0, num_epochs=5, experiment_name='vitb16_birds_224_224', use_gpu=True, weight_decay_coefficient=0.0005, learning_rate=0.001, model='vitb16', pretrain='imagenet', dataloader='birds', height=224, width=224)
Number of training samples:  4495
Number of validation samples:  1499
Number of testing samples:  5794
Number of classes: 200
Use Multi GPU 0
here
System learnable parameters
DataParallel(
  (module): VisionTransformer(
    (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
    (encoder): Encoder(
      (dropout): Dropout(p=0.0, inplace=False)
      (layers): Sequential(
        (encoder_layer_0): EncoderBlock(
          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): MLPBlock(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (encoder_layer_1): EncoderBlock(
          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): MLPBlock(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (encoder_layer_2): EncoderBlock(
          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): MLPBlock(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (encoder_layer_3): EncoderBlock(
          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): MLPBlock(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (encoder_layer_4): EncoderBlock(
          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): MLPBlock(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (encoder_layer_5): EncoderBlock(
          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): MLPBlock(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (encoder_layer_6): EncoderBlock(
          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): MLPBlock(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (encoder_layer_7): EncoderBlock(
          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): MLPBlock(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (encoder_layer_8): EncoderBlock(
          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): MLPBlock(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (encoder_layer_9): EncoderBlock(
          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): MLPBlock(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (encoder_layer_10): EncoderBlock(
          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): MLPBlock(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
        (encoder_layer_11): EncoderBlock(
          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (self_attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): MLPBlock(
            (0): Linear(in_features=768, out_features=3072, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.0, inplace=False)
            (3): Linear(in_features=3072, out_features=768, bias=True)
            (4): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    )
    (heads): Sequential(
      (head): Linear(in_features=768, out_features=200, bias=True)
    )
  )
)
  0%|          | 0/71 [00:00<?, ?it/s]  1%|▏         | 1/71 [01:20<1:34:18, 80.84s/it]loss: 1.0828, accuracy: 1.0000:   1%|▏         | 1/71 [01:20<1:34:18, 80.84s/it]loss: 1.0828, accuracy: 1.0000:   3%|▎         | 2/71 [02:00<1:05:18, 56.79s/it]loss: 1.0778, accuracy: 1.0000:   3%|▎         | 2/71 [02:00<1:05:18, 56.79s/it]loss: 1.0778, accuracy: 1.0000:   4%|▍         | 3/71 [02:40<55:40, 49.12s/it]  loss: 1.0815, accuracy: 1.0000:   4%|▍         | 3/71 [02:40<55:40, 49.12s/it]loss: 1.0815, accuracy: 1.0000:   6%|▌         | 4/71 [03:21<51:01, 45.70s/it]loss: 1.0786, accuracy: 1.0000:   6%|▌         | 4/71 [03:21<51:01, 45.70s/it]loss: 1.0786, accuracy: 1.0000:   7%|▋         | 5/71 [04:01<48:04, 43.71s/it]loss: 1.0760, accuracy: 1.0000:   7%|▋         | 5/71 [04:01<48:04, 43.71s/it]loss: 1.0760, accuracy: 1.0000:   8%|▊         | 6/71 [04:42<46:22, 42.81s/it]loss: 1.0814, accuracy: 1.0000:   8%|▊         | 6/71 [04:42<46:22, 42.81s/it]loss: 1.0814, accuracy: 1.0000:  10%|▉         | 7/71 [05:24<45:13, 42.40s/it]loss: 1.0796, accuracy: 1.0000:  10%|▉         | 7/71 [05:24<45:13, 42.40s/it]loss: 1.0796, accuracy: 1.0000:  11%|█▏        | 8/71 [06:05<44:08, 42.04s/it]loss: 1.0798, accuracy: 1.0000:  11%|█▏        | 8/71 [06:05<44:08, 42.04s/it]loss: 1.0798, accuracy: 1.0000:  13%|█▎        | 9/71 [06:46<43:08, 41.75s/it]loss: 1.0755, accuracy: 1.0000:  13%|█▎        | 9/71 [06:46<43:08, 41.75s/it]loss: 1.0755, accuracy: 1.0000:  14%|█▍        | 10/71 [07:27<42:07, 41.43s/it]loss: 1.0719, accuracy: 1.0000:  14%|█▍        | 10/71 [07:27<42:07, 41.43s/it]loss: 1.0719, accuracy: 1.0000:  15%|█▌        | 11/71 [08:08<41:25, 41.42s/it]loss: 1.0811, accuracy: 1.0000:  15%|█▌        | 11/71 [08:08<41:25, 41.42s/it]loss: 1.0811, accuracy: 1.0000:  17%|█▋        | 12/71 [08:49<40:37, 41.31s/it]loss: 1.0785, accuracy: 1.0000:  17%|█▋        | 12/71 [08:49<40:37, 41.31s/it]loss: 1.0785, accuracy: 1.0000:  18%|█▊        | 13/71 [09:30<39:56, 41.33s/it]loss: 1.0821, accuracy: 1.0000:  18%|█▊        | 13/71 [09:30<39:56, 41.33s/it]loss: 1.0821, accuracy: 1.0000:  20%|█▉        | 14/71 [10:05<37:16, 39.24s/it]loss: 1.0784, accuracy: 1.0000:  20%|█▉        | 14/71 [10:05<37:16, 39.24s/it]loss: 1.0784, accuracy: 1.0000:  21%|██        | 15/71 [10:31<32:55, 35.27s/it]loss: 1.0822, accuracy: 1.0000:  21%|██        | 15/71 [10:31<32:55, 35.27s/it]loss: 1.0822, accuracy: 1.0000:  23%|██▎       | 16/71 [10:57<29:51, 32.58s/it]loss: 1.0797, accuracy: 1.0000:  23%|██▎       | 16/71 [10:57<29:51, 32.58s/it]loss: 1.0797, accuracy: 1.0000:  24%|██▍       | 17/71 [11:23<27:34, 30.64s/it]loss: 1.0817, accuracy: 1.0000:  24%|██▍       | 17/71 [11:23<27:34, 30.64s/it]loss: 1.0817, accuracy: 1.0000:  25%|██▌       | 18/71 [11:50<25:52, 29.29s/it]loss: 1.0748, accuracy: 1.0000:  25%|██▌       | 18/71 [11:50<25:52, 29.29s/it]loss: 1.0748, accuracy: 1.0000:  27%|██▋       | 19/71 [12:15<24:30, 28.28s/it]loss: 1.0768, accuracy: 1.0000:  27%|██▋       | 19/71 [12:15<24:30, 28.28s/it]loss: 1.0768, accuracy: 1.0000:  28%|██▊       | 20/71 [12:42<23:30, 27.65s/it]loss: 1.0777, accuracy: 1.0000:  28%|██▊       | 20/71 [12:42<23:30, 27.65s/it]loss: 1.0777, accuracy: 1.0000:  30%|██▉       | 21/71 [13:08<22:38, 27.18s/it]loss: 1.0771, accuracy: 1.0000:  30%|██▉       | 21/71 [13:08<22:38, 27.18s/it]loss: 1.0771, accuracy: 1.0000:  31%|███       | 22/71 [13:34<21:55, 26.85s/it]loss: 1.0752, accuracy: 1.0000:  31%|███       | 22/71 [13:34<21:55, 26.85s/it]loss: 1.0752, accuracy: 1.0000:  32%|███▏      | 23/71 [14:00<21:15, 26.57s/it]loss: 1.0782, accuracy: 1.0000:  32%|███▏      | 23/71 [14:00<21:15, 26.57s/it]loss: 1.0782, accuracy: 1.0000:  34%|███▍      | 24/71 [14:26<20:43, 26.46s/it]loss: 1.0795, accuracy: 1.0000:  34%|███▍      | 24/71 [14:26<20:43, 26.46s/it]loss: 1.0795, accuracy: 1.0000:  35%|███▌      | 25/71 [14:52<20:10, 26.32s/it]loss: 1.0865, accuracy: 1.0000:  35%|███▌      | 25/71 [14:52<20:10, 26.32s/it]loss: 1.0865, accuracy: 1.0000:  37%|███▋      | 26/71 [15:19<19:51, 26.48s/it]loss: 1.0712, accuracy: 1.0000:  37%|███▋      | 26/71 [15:19<19:51, 26.48s/it]loss: 1.0712, accuracy: 1.0000:  38%|███▊      | 27/71 [15:45<19:18, 26.33s/it]loss: 1.0784, accuracy: 1.0000:  38%|███▊      | 27/71 [15:45<19:18, 26.33s/it]loss: 1.0784, accuracy: 1.0000:  39%|███▉      | 28/71 [16:11<18:51, 26.31s/it]loss: 1.0745, accuracy: 1.0000:  39%|███▉      | 28/71 [16:11<18:51, 26.31s/it]loss: 1.0745, accuracy: 1.0000:  41%|████      | 29/71 [16:37<18:21, 26.22s/it]loss: 1.0738, accuracy: 1.0000:  41%|████      | 29/71 [16:37<18:21, 26.22s/it]loss: 1.0738, accuracy: 1.0000:  42%|████▏     | 30/71 [17:03<17:53, 26.19s/it]loss: 1.0725, accuracy: 1.0000:  42%|████▏     | 30/71 [17:03<17:53, 26.19s/it]loss: 1.0725, accuracy: 1.0000:  44%|████▎     | 31/71 [17:29<17:26, 26.16s/it]loss: 1.0830, accuracy: 1.0000:  44%|████▎     | 31/71 [17:29<17:26, 26.16s/it]loss: 1.0830, accuracy: 1.0000:  45%|████▌     | 32/71 [17:55<17:00, 26.16s/it]loss: 1.0680, accuracy: 1.0000:  45%|████▌     | 32/71 [17:55<17:00, 26.16s/it]loss: 1.0680, accuracy: 1.0000:  46%|████▋     | 33/71 [18:21<16:31, 26.08s/it]loss: 1.0681, accuracy: 1.0000:  46%|████▋     | 33/71 [18:21<16:31, 26.08s/it]loss: 1.0681, accuracy: 1.0000:  48%|████▊     | 34/71 [18:48<16:07, 26.14s/it]loss: 1.0819, accuracy: 1.0000:  48%|████▊     | 34/71 [18:48<16:07, 26.14s/it]loss: 1.0819, accuracy: 1.0000:  49%|████▉     | 35/71 [19:14<15:39, 26.10s/it]loss: 1.0867, accuracy: 1.0000:  49%|████▉     | 35/71 [19:14<15:39, 26.10s/it]loss: 1.0867, accuracy: 1.0000:  51%|█████     | 36/71 [19:40<15:14, 26.14s/it]loss: 1.0803, accuracy: 1.0000:  51%|█████     | 36/71 [19:40<15:14, 26.14s/it]loss: 1.0803, accuracy: 1.0000:  52%|█████▏    | 37/71 [20:06<14:47, 26.11s/it]loss: 1.0765, accuracy: 1.0000:  52%|█████▏    | 37/71 [20:06<14:47, 26.11s/it]loss: 1.0765, accuracy: 1.0000:  54%|█████▎    | 38/71 [20:32<14:22, 26.14s/it]loss: 1.0781, accuracy: 1.0000:  54%|█████▎    | 38/71 [20:32<14:22, 26.14s/it]loss: 1.0781, accuracy: 1.0000:  55%|█████▍    | 39/71 [20:59<14:01, 26.30s/it]loss: 1.0748, accuracy: 1.0000:  55%|█████▍    | 39/71 [20:59<14:01, 26.30s/it]loss: 1.0748, accuracy: 1.0000:  56%|█████▋    | 40/71 [21:25<13:34, 26.27s/it]loss: 1.0663, accuracy: 1.0000:  56%|█████▋    | 40/71 [21:25<13:34, 26.27s/it]loss: 1.0663, accuracy: 1.0000:  58%|█████▊    | 41/71 [21:51<13:05, 26.18s/it]loss: 1.0791, accuracy: 1.0000:  58%|█████▊    | 41/71 [21:51<13:05, 26.18s/it]loss: 1.0791, accuracy: 1.0000:  59%|█████▉    | 42/71 [22:17<12:38, 26.16s/it]loss: 1.0792, accuracy: 1.0000:  59%|█████▉    | 42/71 [22:17<12:38, 26.16s/it]loss: 1.0792, accuracy: 1.0000:  61%|██████    | 43/71 [22:43<12:12, 26.16s/it]loss: 1.0737, accuracy: 1.0000:  61%|██████    | 43/71 [22:43<12:12, 26.16s/it]loss: 1.0737, accuracy: 1.0000:  62%|██████▏   | 44/71 [23:10<11:47, 26.20s/it]loss: 1.0793, accuracy: 1.0000:  62%|██████▏   | 44/71 [23:10<11:47, 26.20s/it]loss: 1.0793, accuracy: 1.0000:  63%|██████▎   | 45/71 [23:36<11:20, 26.16s/it]loss: 1.0864, accuracy: 1.0000:  63%|██████▎   | 45/71 [23:36<11:20, 26.16s/it]loss: 1.0864, accuracy: 1.0000:  65%|██████▍   | 46/71 [24:02<10:54, 26.19s/it]loss: 1.0710, accuracy: 1.0000:  65%|██████▍   | 46/71 [24:02<10:54, 26.19s/it]loss: 1.0710, accuracy: 1.0000:  66%|██████▌   | 47/71 [24:28<10:27, 26.14s/it]loss: 1.0692, accuracy: 1.0000:  66%|██████▌   | 47/71 [24:28<10:27, 26.14s/it]loss: 1.0692, accuracy: 1.0000:  68%|██████▊   | 48/71 [24:54<10:01, 26.15s/it]loss: 1.0755, accuracy: 1.0000:  68%|██████▊   | 48/71 [24:54<10:01, 26.15s/it]loss: 1.0755, accuracy: 1.0000:  69%|██████▉   | 49/71 [25:20<09:34, 26.11s/it]loss: 1.0762, accuracy: 1.0000:  69%|██████▉   | 49/71 [25:20<09:34, 26.11s/it]loss: 1.0762, accuracy: 1.0000:  70%|███████   | 50/71 [25:46<09:09, 26.18s/it]loss: 1.0784, accuracy: 1.0000:  70%|███████   | 50/71 [25:46<09:09, 26.18s/it]loss: 1.0784, accuracy: 1.0000:  72%|███████▏  | 51/71 [26:13<08:45, 26.28s/it]loss: 1.0846, accuracy: 1.0000:  72%|███████▏  | 51/71 [26:13<08:45, 26.28s/it]loss: 1.0846, accuracy: 1.0000:  73%|███████▎  | 52/71 [26:39<08:19, 26.28s/it]loss: 1.0703, accuracy: 1.0000:  73%|███████▎  | 52/71 [26:39<08:19, 26.28s/it]loss: 1.0703, accuracy: 1.0000:  75%|███████▍  | 53/71 [27:05<07:52, 26.23s/it]loss: 1.0804, accuracy: 1.0000:  75%|███████▍  | 53/71 [27:05<07:52, 26.23s/it]loss: 1.0804, accuracy: 1.0000:  76%|███████▌  | 54/71 [27:32<07:26, 26.25s/it]loss: 1.0860, accuracy: 1.0000:  76%|███████▌  | 54/71 [27:32<07:26, 26.25s/it]loss: 1.0860, accuracy: 1.0000:  77%|███████▋  | 55/71 [27:58<06:59, 26.19s/it]loss: 1.0880, accuracy: 1.0000:  77%|███████▋  | 55/71 [27:58<06:59, 26.19s/it]loss: 1.0880, accuracy: 1.0000:  79%|███████▉  | 56/71 [28:24<06:33, 26.24s/it]loss: 1.0851, accuracy: 1.0000:  79%|███████▉  | 56/71 [28:24<06:33, 26.24s/it]loss: 1.0851, accuracy: 1.0000:  80%|████████  | 57/71 [28:50<06:07, 26.22s/it]loss: 1.0797, accuracy: 1.0000:  80%|████████  | 57/71 [28:50<06:07, 26.22s/it]loss: 1.0797, accuracy: 1.0000:  82%|████████▏ | 58/71 [29:16<05:40, 26.22s/it]loss: 1.0768, accuracy: 1.0000:  82%|████████▏ | 58/71 [29:16<05:40, 26.22s/it]loss: 1.0768, accuracy: 1.0000:  83%|████████▎ | 59/71 [29:42<05:13, 26.16s/it]loss: 1.0891, accuracy: 1.0000:  83%|████████▎ | 59/71 [29:42<05:13, 26.16s/it]loss: 1.0891, accuracy: 1.0000:  85%|████████▍ | 60/71 [30:09<04:48, 26.21s/it]loss: 1.0769, accuracy: 1.0000:  85%|████████▍ | 60/71 [30:09<04:48, 26.21s/it]loss: 1.0769, accuracy: 1.0000:  86%|████████▌ | 61/71 [30:35<04:21, 26.16s/it]loss: 1.0718, accuracy: 1.0000:  86%|████████▌ | 61/71 [30:35<04:21, 26.16s/it]loss: 1.0718, accuracy: 1.0000:  87%|████████▋ | 62/71 [31:01<03:55, 26.17s/it]loss: 1.0738, accuracy: 1.0000:  87%|████████▋ | 62/71 [31:01<03:55, 26.17s/it]loss: 1.0738, accuracy: 1.0000:  89%|████████▊ | 63/71 [31:27<03:29, 26.17s/it]loss: 1.0814, accuracy: 1.0000:  89%|████████▊ | 63/71 [31:27<03:29, 26.17s/it]loss: 1.0814, accuracy: 1.0000:  90%|█████████ | 64/71 [31:54<03:04, 26.37s/it]loss: 1.0797, accuracy: 1.0000:  90%|█████████ | 64/71 [31:54<03:04, 26.37s/it]loss: 1.0797, accuracy: 1.0000:  92%|█████████▏| 65/71 [32:20<02:37, 26.26s/it]loss: 1.0810, accuracy: 1.0000:  92%|█████████▏| 65/71 [32:20<02:37, 26.26s/it]loss: 1.0810, accuracy: 1.0000:  93%|█████████▎| 66/71 [32:46<02:11, 26.25s/it]loss: 1.0746, accuracy: 1.0000:  93%|█████████▎| 66/71 [32:46<02:11, 26.25s/it]loss: 1.0746, accuracy: 1.0000:  94%|█████████▍| 67/71 [33:12<01:44, 26.22s/it]loss: 1.0785, accuracy: 1.0000:  94%|█████████▍| 67/71 [33:12<01:44, 26.22s/it]loss: 1.0785, accuracy: 1.0000:  96%|█████████▌| 68/71 [33:39<01:18, 26.26s/it]loss: 1.0741, accuracy: 1.0000:  96%|█████████▌| 68/71 [33:39<01:18, 26.26s/it]loss: 1.0741, accuracy: 1.0000:  97%|█████████▋| 69/71 [34:05<00:52, 26.21s/it]loss: 1.0797, accuracy: 1.0000:  97%|█████████▋| 69/71 [34:05<00:52, 26.21s/it]loss: 1.0797, accuracy: 1.0000:  99%|█████████▊| 70/71 [34:31<00:26, 26.25s/it]loss: 1.0690, accuracy: 1.0000:  99%|█████████▊| 70/71 [34:31<00:26, 26.25s/it]loss: 1.0690, accuracy: 1.0000: 100%|██████████| 71/71 [34:39<00:00, 20.60s/it]loss: 1.0604, accuracy: 1.0000: 100%|██████████| 71/71 [34:39<00:00, 20.60s/it]loss: 1.0604, accuracy: 1.0000: 100%|██████████| 71/71 [34:39<00:00, 29.28s/it]
  0%|          | 0/24 [00:00<?, ?it/s]  4%|▍         | 1/24 [00:24<09:34, 24.98s/it]loss: 2.9630, accuracy: 0.5312:   4%|▍         | 1/24 [00:24<09:34, 24.98s/it]loss: 2.9630, accuracy: 0.5312:   8%|▊         | 2/24 [00:50<09:12, 25.11s/it]loss: 2.6196, accuracy: 0.6406:   8%|▊         | 2/24 [00:50<09:12, 25.11s/it]loss: 2.6196, accuracy: 0.6406:  12%|█▎        | 3/24 [01:15<08:45, 25.04s/it]loss: 2.8844, accuracy: 0.6094:  12%|█▎        | 3/24 [01:15<08:45, 25.04s/it]loss: 2.8844, accuracy: 0.6094:  17%|█▋        | 4/24 [01:40<08:22, 25.12s/it]loss: 2.8786, accuracy: 0.5938:  17%|█▋        | 4/24 [01:40<08:22, 25.12s/it]loss: 2.8786, accuracy: 0.5938:  21%|██        | 5/24 [02:05<07:56, 25.09s/it]loss: 2.9302, accuracy: 0.6094:  21%|██        | 5/24 [02:05<07:56, 25.09s/it]loss: 2.9302, accuracy: 0.6094:  25%|██▌       | 6/24 [02:30<07:32, 25.12s/it]loss: 2.6034, accuracy: 0.5625:  25%|██▌       | 6/24 [02:30<07:32, 25.12s/it]loss: 2.6034, accuracy: 0.5625:  29%|██▉       | 7/24 [02:55<07:06, 25.11s/it]loss: 3.3369, accuracy: 0.5156:  29%|██▉       | 7/24 [02:55<07:06, 25.11s/it]loss: 3.3369, accuracy: 0.5156:  33%|███▎      | 8/24 [03:21<06:45, 25.33s/it]loss: 3.5513, accuracy: 0.5000:  33%|███▎      | 8/24 [03:21<06:45, 25.33s/it]loss: 3.5513, accuracy: 0.5000:  38%|███▊      | 9/24 [03:46<06:17, 25.19s/it]loss: 3.6994, accuracy: 0.3750:  38%|███▊      | 9/24 [03:46<06:17, 25.19s/it]loss: 3.6994, accuracy: 0.3750:  42%|████▏     | 10/24 [04:11<05:52, 25.18s/it]loss: 2.9999, accuracy: 0.5312:  42%|████▏     | 10/24 [04:11<05:52, 25.18s/it]loss: 2.9999, accuracy: 0.5312:  46%|████▌     | 11/24 [04:36<05:26, 25.14s/it]loss: 3.2447, accuracy: 0.4688:  46%|████▌     | 11/24 [04:36<05:26, 25.14s/it]loss: 3.2447, accuracy: 0.4688:  50%|█████     | 12/24 [05:01<05:01, 25.14s/it]loss: 3.3935, accuracy: 0.3438:  50%|█████     | 12/24 [05:01<05:01, 25.14s/it]loss: 3.3935, accuracy: 0.3438:  54%|█████▍    | 13/24 [05:26<04:35, 25.09s/it]loss: 2.9201, accuracy: 0.5938:  54%|█████▍    | 13/24 [05:26<04:35, 25.09s/it]loss: 2.9201, accuracy: 0.5938:  58%|█████▊    | 14/24 [05:51<04:11, 25.15s/it]loss: 3.5719, accuracy: 0.3906:  58%|█████▊    | 14/24 [05:51<04:11, 25.15s/it]loss: 3.5719, accuracy: 0.3906:  62%|██████▎   | 15/24 [06:17<03:46, 25.12s/it]loss: 3.1159, accuracy: 0.5156:  62%|██████▎   | 15/24 [06:17<03:46, 25.12s/it]loss: 3.1159, accuracy: 0.5156:  67%|██████▋   | 16/24 [06:42<03:21, 25.13s/it]loss: 2.9023, accuracy: 0.5312:  67%|██████▋   | 16/24 [06:42<03:21, 25.13s/it]loss: 2.9023, accuracy: 0.5312:  71%|███████   | 17/24 [07:07<02:55, 25.08s/it]loss: 3.7715, accuracy: 0.3438:  71%|███████   | 17/24 [07:07<02:55, 25.08s/it]loss: 3.7715, accuracy: 0.3438:  75%|███████▌  | 18/24 [07:32<02:30, 25.14s/it]loss: 2.6654, accuracy: 0.5781:  75%|███████▌  | 18/24 [07:32<02:30, 25.14s/it]loss: 2.6654, accuracy: 0.5781:  79%|███████▉  | 19/24 [07:57<02:05, 25.09s/it]loss: 2.9614, accuracy: 0.5156:  79%|███████▉  | 19/24 [07:57<02:05, 25.09s/it]loss: 2.9614, accuracy: 0.5156:  83%|████████▎ | 20/24 [08:22<01:40, 25.13s/it]loss: 3.5427, accuracy: 0.4062:  83%|████████▎ | 20/24 [08:22<01:40, 25.13s/it]loss: 3.5427, accuracy: 0.4062:  88%|████████▊ | 21/24 [08:48<01:15, 25.26s/it]loss: 2.8526, accuracy: 0.6406:  88%|████████▊ | 21/24 [08:48<01:15, 25.26s/it]loss: 2.8526, accuracy: 0.6406:  92%|█████████▏| 22/24 [09:13<00:50, 25.25s/it]loss: 2.9630, accuracy: 0.5625:  92%|█████████▏| 22/24 [09:13<00:50, 25.25s/it]loss: 2.9630, accuracy: 0.5625:  96%|█████████▌| 23/24 [09:38<00:25, 25.19s/it]loss: 2.8962, accuracy: 0.5625:  96%|█████████▌| 23/24 [09:38<00:25, 25.19s/it]loss: 2.8962, accuracy: 0.5625: 100%|██████████| 24/24 [09:57<00:00, 23.23s/it]loss: 2.8653, accuracy: 0.5556: 100%|██████████| 24/24 [09:57<00:00, 23.23s/it]loss: 2.8653, accuracy: 0.5556: 100%|██████████| 24/24 [09:57<00:00, 24.88s/it]
Epoch 60: train_acc_1.0000_train_loss_1.0777_val_acc_0.5199_val_loss_3.0889 epoch time 2676.2689 seconds
  0%|          | 0/71 [00:00<?, ?it/s]  1%|▏         | 1/71 [00:26<30:35, 26.23s/it]loss: 1.0837, accuracy: 1.0000:   1%|▏         | 1/71 [00:26<30:35, 26.23s/it]loss: 1.0837, accuracy: 1.0000:   3%|▎         | 2/71 [00:52<29:58, 26.07s/it]loss: 1.0805, accuracy: 1.0000:   3%|▎         | 2/71 [00:52<29:58, 26.07s/it]loss: 1.0805, accuracy: 1.0000:   4%|▍         | 3/71 [01:18<29:33, 26.08s/it]loss: 1.0876, accuracy: 1.0000:   4%|▍         | 3/71 [01:18<29:33, 26.08s/it]loss: 1.0876, accuracy: 1.0000:   6%|▌         | 4/71 [01:44<29:04, 26.03s/it]loss: 1.0783, accuracy: 1.0000:   6%|▌         | 4/71 [01:44<29:04, 26.03s/it]loss: 1.0783, accuracy: 1.0000:   7%|▋         | 5/71 [02:10<28:41, 26.08s/it]loss: 1.0787, accuracy: 1.0000:   7%|▋         | 5/71 [02:10<28:41, 26.08s/it]loss: 1.0787, accuracy: 1.0000:   8%|▊         | 6/71 [02:36<28:11, 26.03s/it]loss: 1.0759, accuracy: 1.0000:   8%|▊         | 6/71 [02:36<28:11, 26.03s/it]loss: 1.0759, accuracy: 1.0000:  10%|▉         | 7/71 [03:03<27:59, 26.25s/it]loss: 1.0681, accuracy: 1.0000:  10%|▉         | 7/71 [03:03<27:59, 26.25s/it]loss: 1.0681, accuracy: 1.0000:  11%|█▏        | 8/71 [03:29<27:28, 26.17s/it]loss: 1.0743, accuracy: 1.0000:  11%|█▏        | 8/71 [03:29<27:28, 26.17s/it]loss: 1.0743, accuracy: 1.0000:  13%|█▎        | 9/71 [03:55<27:03, 26.18s/it]loss: 1.0682, accuracy: 1.0000:  13%|█▎        | 9/71 [03:55<27:03, 26.18s/it]loss: 1.0682, accuracy: 1.0000:  14%|█▍        | 10/71 [04:21<26:34, 26.13s/it]loss: 1.0731, accuracy: 1.0000:  14%|█▍        | 10/71 [04:21<26:34, 26.13s/it]loss: 1.0731, accuracy: 1.0000:  15%|█▌        | 11/71 [04:47<26:08, 26.13s/it]loss: 1.0770, accuracy: 1.0000:  15%|█▌        | 11/71 [04:47<26:08, 26.13s/it]loss: 1.0770, accuracy: 1.0000:  17%|█▋        | 12/71 [05:13<25:39, 26.09s/it]loss: 1.0809, accuracy: 1.0000:  17%|█▋        | 12/71 [05:13<25:39, 26.09s/it]loss: 1.0809, accuracy: 1.0000:  18%|█▊        | 13/71 [05:39<25:13, 26.10s/it]loss: 1.0824, accuracy: 1.0000:  18%|█▊        | 13/71 [05:39<25:13, 26.10s/it]loss: 1.0824, accuracy: 1.0000:  20%|█▉        | 14/71 [06:05<24:45, 26.07s/it]loss: 1.0817, accuracy: 1.0000:  20%|█▉        | 14/71 [06:05<24:45, 26.07s/it]loss: 1.0817, accuracy: 1.0000:  21%|██        | 15/71 [06:31<24:19, 26.07s/it]loss: 1.0743, accuracy: 1.0000:  21%|██        | 15/71 [06:31<24:19, 26.07s/it]loss: 1.0743, accuracy: 1.0000:  23%|██▎       | 16/71 [06:57<23:52, 26.04s/it]loss: 1.0767, accuracy: 1.0000:  23%|██▎       | 16/71 [06:57<23:52, 26.04s/it]loss: 1.0767, accuracy: 1.0000:  24%|██▍       | 17/71 [07:23<23:27, 26.07s/it]loss: 1.0710, accuracy: 1.0000:  24%|██▍       | 17/71 [07:23<23:27, 26.07s/it]loss: 1.0710, accuracy: 1.0000:  25%|██▌       | 18/71 [07:49<22:58, 26.02s/it]loss: 1.0769, accuracy: 1.0000:  25%|██▌       | 18/71 [07:49<22:58, 26.02s/it]loss: 1.0769, accuracy: 1.0000:  27%|██▋       | 19/71 [08:16<22:45, 26.25s/it]loss: 1.0722, accuracy: 1.0000:  27%|██▋       | 19/71 [08:16<22:45, 26.25s/it]loss: 1.0722, accuracy: 1.0000:  28%|██▊       | 20/71 [08:42<22:14, 26.18s/it]loss: 1.0790, accuracy: 1.0000:  28%|██▊       | 20/71 [08:42<22:14, 26.18s/it]loss: 1.0790, accuracy: 1.0000:  30%|██▉       | 21/71 [09:08<21:47, 26.15s/it]loss: 1.0750, accuracy: 1.0000:  30%|██▉       | 21/71 [09:08<21:47, 26.15s/it]loss: 1.0750, accuracy: 1.0000:  31%|███       | 22/71 [09:34<21:20, 26.13s/it]loss: 1.0726, accuracy: 1.0000:  31%|███       | 22/71 [09:34<21:20, 26.13s/it]loss: 1.0726, accuracy: 1.0000:  32%|███▏      | 23/71 [10:00<20:53, 26.12s/it]loss: 1.0771, accuracy: 1.0000:  32%|███▏      | 23/71 [10:00<20:53, 26.12s/it]loss: 1.0771, accuracy: 1.0000:  34%|███▍      | 24/71 [10:26<20:24, 26.05s/it]loss: 1.0855, accuracy: 1.0000:  34%|███▍      | 24/71 [10:26<20:24, 26.05s/it]loss: 1.0855, accuracy: 1.0000:  35%|███▌      | 25/71 [10:52<20:00, 26.09s/it]loss: 1.0766, accuracy: 1.0000:  35%|███▌      | 25/71 [10:52<20:00, 26.09s/it]loss: 1.0766, accuracy: 1.0000:  37%|███▋      | 26/71 [11:18<19:33, 26.08s/it]loss: 1.0811, accuracy: 1.0000:  37%|███▋      | 26/71 [11:18<19:33, 26.08s/it]loss: 1.0811, accuracy: 1.0000:  38%|███▊      | 27/71 [11:44<19:09, 26.12s/it]loss: 1.0764, accuracy: 1.0000:  38%|███▊      | 27/71 [11:44<19:09, 26.12s/it]loss: 1.0764, accuracy: 1.0000:  39%|███▉      | 28/71 [12:10<18:41, 26.08s/it]loss: 1.0803, accuracy: 1.0000:  39%|███▉      | 28/71 [12:10<18:41, 26.08s/it]loss: 1.0803, accuracy: 1.0000:  41%|████      | 29/71 [12:37<18:15, 26.09s/it]loss: 1.0782, accuracy: 1.0000:  41%|████      | 29/71 [12:37<18:15, 26.09s/it]loss: 1.0782, accuracy: 1.0000:  42%|████▏     | 30/71 [13:03<17:48, 26.05s/it]loss: 1.0750, accuracy: 1.0000:  42%|████▏     | 30/71 [13:03<17:48, 26.05s/it]loss: 1.0750, accuracy: 1.0000:  44%|████▎     | 31/71 [13:29<17:24, 26.12s/it]loss: 1.0753, accuracy: 1.0000:  44%|████▎     | 31/71 [13:29<17:24, 26.12s/it]loss: 1.0753, accuracy: 1.0000:  45%|████▌     | 32/71 [13:55<17:04, 26.26s/it]loss: 1.0838, accuracy: 1.0000:  45%|████▌     | 32/71 [13:55<17:04, 26.26s/it]loss: 1.0838, accuracy: 1.0000:  46%|████▋     | 33/71 [14:22<16:36, 26.22s/it]loss: 1.0922, accuracy: 1.0000:  46%|████▋     | 33/71 [14:22<16:36, 26.22s/it]loss: 1.0922, accuracy: 1.0000:  48%|████▊     | 34/71 [14:48<16:07, 26.14s/it]loss: 1.0902, accuracy: 1.0000:  48%|████▊     | 34/71 [14:48<16:07, 26.14s/it]loss: 1.0902, accuracy: 1.0000:  49%|████▉     | 35/71 [15:14<15:41, 26.16s/it]loss: 1.0792, accuracy: 1.0000:  49%|████▉     | 35/71 [15:14<15:41, 26.16s/it]slurmstepd-landonia10: error: *** JOB 1792738 ON landonia10 CANCELLED AT 2024-03-21T20:24:09 ***
